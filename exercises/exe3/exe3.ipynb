{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext # required for reading input dataset. (data preprocessing step)\n",
    "import matplotlib.pyplot as plt # required for plotting. (Task 1.d)\n",
    "import pandas as pd # required for plotting histograms. (Tasks 1.d, 8)\n",
    "import pyspark.sql.functions as F # required for aggregating functions: min, max, mean, count, size, collect_list, isnan\n",
    "\n",
    "from pyspark.sql.functions import lit, col, udf # col is required for renaming aggregated columns & count for plotting histograms. (Task 3.b) udf is required for counting tokens (Task 8.a)\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer # required for tokenization. (Task 8.a)\n",
    "from pyspark.sql.types import ArrayType,IntegerType, DoubleType # required for counting tokens. (Task 8.a)\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import numpy as np\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import StopWordsRemover, CountVectorizer, HashingTF, IDF # required for removing stop words (Task 8.b)\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, MultilabelMetrics\n",
    "from pyspark.sql import Window, Row\n",
    "from handyspark import *\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# required for plotting. (Task 3.b)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================\n",
    "#Common variables:\n",
    "#=================\n",
    "\n",
    "# Display records configuration:\n",
    "#-------------------------------\n",
    "numOfTopRecords = 10 # Default number of top records to display\n",
    "minimalNumOfTopRecords = 2 # Minimum number of top records to display\n",
    "\n",
    "# Cynical words configuration\n",
    "#-----------------------------\n",
    "minimalNumOfPositiveWords = 14 # The minimum number of positive words to filter in,for considering a word as cynical\n",
    "maximumNumOfNegativeWords = 2 # The maximun number of negative words to filter in, for considering a word as cynical\n",
    "\n",
    "# Histogram configuration\n",
    "#------------------------\n",
    "numOfBinsInHistogramOfContinueosValues = 100\n",
    "\n",
    "\n",
    "# Classifiers configuration:\n",
    "#---------------------------\n",
    "shift = 1 # classification algorithms will name the class, by the index. But the minimal score is 1, so the indices should be shifted by 1 unit.\n",
    "scores = [1,2,3,4,5] # Possible scores - these are the labels of the classifiers.\n",
    "randomSplit = [0.7, 0.3] # The split ration of the dataset. First element for traning set, and second element for test set.\n",
    "\n",
    "# Sampling records configuration:\n",
    "#--------------------------------\n",
    "numOfSamplingDefaultRecords = 10000\n",
    "numOfSamplingBadRecords = 10\n",
    "numOfSamplingCynicalRecords = 6\n",
    "\n",
    "# TF & TF-IDF configuration:\n",
    "#---------------------------\n",
    "tfNumOfFeatures = 1000\n",
    "minDocFreq = 6\n",
    "\n",
    "# Grid param (cross validation) configuration:\n",
    "#---------------------------------------------\n",
    "numOfFolds = 3\n",
    "smoothingGridParam = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "numOfFeaturesGridParam = [1000, 5000, 10000]\n",
    "regGridParam = [0.1, 0.3, 0.5, 0.01, 0.03, 0.05]\n",
    "elasticNetGridParam = [0.0, 0.1, 0.2]\n",
    "maxIterGridParam = [10, 20, 50]\n",
    "crossValidationParallelism = 8\n",
    "\n",
    "# Seed configuration:\n",
    "#--------------------\n",
    "filterWordsSeed = 41\n",
    "dataSplitSeed = 1234\n",
    "clusterSeed = 42\n",
    "sampleRecordsSeed = 47\n",
    "\n",
    "\n",
    "#=================\n",
    "#Common functions:\n",
    "#=================\n",
    "\n",
    "# Display the dash character ('-') for a given length times\n",
    "def displayMultipleDashes(title, length):\n",
    "    print('-' * length)\n",
    "\n",
    "# Display title, with dash decoration\n",
    "def displayTitle(title):\n",
    "    length = len(title)\n",
    "    print(\"\\n\")\n",
    "    displayMultipleDashes(title, length)\n",
    "    print(title)\n",
    "    displayMultipleDashes(title, length)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Display title, with dash decoration\n",
    "def displaySubTitle(title):\n",
    "    length = len(title)\n",
    "    print(\"\\n\")\n",
    "    print(title)\n",
    "    displayMultipleDashes(title, length)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "#===================\n",
    "#Histogram functions:\n",
    "#===================\n",
    "    \n",
    "# Get aggregated data frame of a given column, and the suitable count.\n",
    "# Parameters:\n",
    "# df - data frame\n",
    "# columnName - name of column to aggregate\n",
    "# columnAlias - alternative name of the columnName\n",
    "# Returns:\n",
    "# aggregated data frame, with 2 columns: alias column, and the suitable count frequiencies column.\n",
    "def getAggregatedDfCount(df, columnName, columnAlias):\n",
    "    return df.groupBy(columnName).agg(F.size(F.collect_list(columnName))).select(col(columnName).alias(columnAlias), col(\"size(collect_list(\" + columnName + \"))\").alias(\"count\"))\n",
    "\n",
    "# Analyze column which contains continueous values, and display a histogram.\n",
    "# aggregated_df - data frame with 2 columns: column and column count.\n",
    "# pandas_df - aggregated_df converted to pandas dataframe.\n",
    "# columnName - name of column to analyze, in aggregated_df\n",
    "# columnAlias - name of column to analyze, in columnAlias\n",
    "# recordName - name of record, which represents the original rows in aggregated_df\n",
    "# numOfBins - number of bins to display in the histogram\n",
    "def analyzeContinuousValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, numOfBins):\n",
    "    \n",
    "    # Show top records with highest frequencies.\n",
    "    print(\"\\ntop \" + repr(numOfTopRecords) + \" \" + columnAlias + \"s with maximum number of \" + recordName + \"s:\")\n",
    "    aggregated_df.orderBy(\"count\", ascending=False).show(numOfTopRecords)\n",
    "    \n",
    "    # Show top records with lowest frequencies.\n",
    "    print(\"\\n \" + repr(numOfTopRecords) + \" \" + columnAlias + \"s with minimum number of \" + recordName + \"s:\")\n",
    "    aggregated_df.orderBy(\"count\").show(numOfTopRecords)\n",
    "\n",
    "    # Create histogram plot.\n",
    "    pandas_df.plot.hist(grid=True, bins=numOfBins, rwidth=1, color='#607c8e')\n",
    "    plt.title('Products reviews')\n",
    "    plt.xlabel(\"#\" + recordName + \"s\")\n",
    "    plt.ylabel(columnAlias + \"s\")\n",
    "    plt.title(\"Histogram of number of \" + recordName + \"s per \" + columnAlias)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    \n",
    "    # Plot histogram.\n",
    "    plt.show()\n",
    "    \n",
    "# Analyze column which contains descrete values, and display a bar graph.\n",
    "# aggregated_df - data frame with 2 columns: column and column count.\n",
    "# pandas_df - aggregated_df converted to pandas dataframe.\n",
    "# columnName - name of column to analyze, in aggregated_df\n",
    "# columnAlias - name of column to analyze, in columnAlias\n",
    "# recordName - name of record, which represents the original rows in aggregated_df\n",
    "# numOfBins - number of bins to display in the bar graph\n",
    "def analyzeDescreteValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, numOfBins):   \n",
    "    # Force convertion of alias column to int type, if conversion fails - don't throw erroes\n",
    "    pandas_df[columnAlias] = pd.to_numeric(pandas_df[columnAlias], errors='coerce').astype(int)\n",
    "    \n",
    "    # Sort alias column in descending order.\n",
    "    pandas_df.sort_values(by=[columnAlias], inplace=True)\n",
    "    \n",
    "    # Remove index column (for diaplay purposes)\n",
    "    blankIndex=[''] * len(pandas_df)\n",
    "    pandas_df.index=blankIndex\n",
    "    \n",
    "    # Display frequncies of alias column.\n",
    "    display(pandas_df.nlargest(numOfBins,columns=columnAlias))\n",
    "    \n",
    "    # Create bar plot\n",
    "    pandas_df.plot(kind='bar',x=columnAlias,y='count')\n",
    "    \n",
    "    # Plot bar graph\n",
    "    plt.show()\n",
    "\n",
    "# Analyze column values frequencies, and plot the results.\n",
    "# Parameters:\n",
    "# df - dataframe\n",
    "# columnName - name of column in df to analyze\n",
    "# columnAlias - alternative name of the columnName. Will be used for display purposes.\n",
    "# recordName - name of record, which represents the original rows in df\n",
    "# columnType - 0 - for descrete values, 1 - for continuous values\n",
    "def analyzeColumn(df, columnName, columnAlias, recordName, columnType):\n",
    "    displayTitle(\"Analyze \" +  columnName + \" column\")\n",
    "    \n",
    "    # group df by columnName as columnAlias.\n",
    "    aggregated_df = getAggregatedDfCount(df, columnName, columnAlias)\n",
    "    \n",
    "    # Convert df to pandas data frame.\n",
    "    pandas_df = aggregated_df.toPandas()\n",
    "    \n",
    "    # Check if current column contains descrere values or continueous values \n",
    "    if columnType == 0: # descrete values column\n",
    "        #  analyze descrete column & plot bar graph\n",
    "        analyzeDescreteValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, columnCountDict[columnName])\n",
    "    else: # columnType == 1 ==> continuous values column\n",
    "        #  analyze continuous column & plot histogram\n",
    "        analyzeContinuousValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, numOfBinsInHistogramOfContinueosValues)\n",
    "    \n",
    "    # Release unused memory\n",
    "    del pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------\n",
      "Loading the data:\n",
      "-----------------\n",
      "\n",
      "\n",
      "Load the dat set from: Reviews.csv\n",
      "Load negative words from: negative-words.txt\n",
      "Load positive words from: positive-words.txt\n",
      "Data has been successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Loading the data:\")\n",
    "dataset_file = \"Reviews.csv\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "\n",
    "\n",
    "# Raise an error, if dataset does not exist\n",
    "# The dataset can be downloaded from this url: https://www.kaggle.com/qwikfix/amazon-recommendation-dataset/data\n",
    "# The expected path of the dataset, should be in the same directory of this jupyter notebook file.\n",
    "if not os.path.exists(dataset_file):\n",
    "    raise ValueError('Dataset file %s does not exist' % dataset_file)\n",
    "    \n",
    "# Raise an error, if negative words file does not exist\n",
    "if not os.path.exists(negative_words_file):\n",
    "    raise ValueError('negative words file %s does not exist' % negative_words_file)\n",
    "    \n",
    "# Raise an error, if positive words file does not exist\n",
    "if not os.path.exists(positive_words_file):\n",
    "    raise ValueError('positive words file %s does not exist' % positive_words_file)\n",
    "\n",
    "print(\"Load the dat set from: \" + dataset_file)\n",
    "reviews = sc.textFile(dataset_file)\n",
    "\n",
    "print(\"Load negative words from: \" + negative_words_file)\n",
    "negative_words_df = spark.read.option(\"header\", \"false\")\\\n",
    "    .option(\"delimiter\", \"\\n\")\\\n",
    "    .csv(negative_words_file)\n",
    "\n",
    "print(\"Load positive words from: \" + positive_words_file)\n",
    "positive_words_df = spark.read.option(\"header\", \"false\")\\\n",
    "    .option(\"delimiter\", \"\\n\")\\\n",
    "    .csv(positive_words_file)\n",
    "\n",
    "print(\"Data has been successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------\n",
      "Preparing the data:\n",
      "-------------------\n",
      "\n",
      "\n",
      "extract header\n",
      "Get columns titles\n",
      "Filter out corrupted records, with invalid number of columns\n",
      "get reviews rdd\n",
      "get reviews data frame\n",
      "\n",
      "\n",
      "Tokenization\n",
      "------------\n",
      "\n",
      "\n",
      "Stop word removal:\n",
      "\n",
      "Get list of stop words to be removed, using StopWordsRemover\n",
      "Define remover, with the list of stop words that have been loaded\n",
      "Remove stop words\n",
      "Add count_filtered column & cast Score column from Double to Integer\n",
      "Display results, after removing stop words\n",
      "Every row's results will be displayed in the following format: Id|Score||Text|words|tokens|filtered|\n",
      "+---+-----+--------------------+--------------------+------+--------------------+--------------+\n",
      "| Id|Score|                Text|               words|tokens|            filtered|count_filtered|\n",
      "+---+-----+--------------------+--------------------+------+--------------------+--------------+\n",
      "|  1|    5|I have bought sev...|[i, have, bought,...|    48|[bought, several,...|            23|\n",
      "|  2|    1|\"Product arrived ...|[product, arrived...|    32|[product, arrived...|            18|\n",
      "|  4|    2|If you are lookin...|[if, you, are, lo...|    41|[looking, secret,...|            18|\n",
      "|  9|    5|Right now I'm mos...|[right, now, i, m...|    27|[right, m, mostly...|            12|\n",
      "| 10|    5|This is a very he...|[this, is, a, ver...|    25|[healthy, dog, fo...|            15|\n",
      "| 14|    4|good flavor! thes...|[good, flavor, th...|    15|[good, flavor, ca...|             9|\n",
      "| 15|    5|The Strawberry Tw...|[the, strawberry,...|    21|[strawberry, twiz...|             9|\n",
      "| 17|    2|I love eating the...|[i, love, eating,...|    42|[love, eating, go...|            18|\n",
      "| 18|    5|I am very satisfi...|[i, am, very, sat...|    25|[satisfied, twizz...|             8|\n",
      "| 20|    5|Candy was deliver...|[candy, was, deli...|    29|[candy, delivered...|            12|\n",
      "| 23|    5|I can remember bu...|[i, can, remember...|    29|[remember, buying...|            13|\n",
      "| 24|    5|I love this candy...|[i, love, this, c...|    19|[love, candy, wei...|             8|\n",
      "| 28|    4|I was so glad Ama...|[i, was, so, glad...|    37|[glad, amazon, ca...|            18|\n",
      "| 43|    5|I have McCann's O...|[i, have, mccann,...|    34|[mccann, oatmeal,...|            19|\n",
      "| 45|    5|We really like th...|[we, really, like...|    48|[really, like, mc...|            25|\n",
      "| 47|    5|Good oatmeal.  I ...|[good, oatmeal, i...|    48|[good, oatmeal, l...|            24|\n",
      "| 50|    3|This is the same ...|[this, is, the, s...|    37|[stuff, buy, big,...|            15|\n",
      "| 54|    3|we're used to spi...|[we, re, used, to...|    34|[re, used, spicy,...|            14|\n",
      "| 57|    5|Deal was awesome!...|[deal, was, aweso...|    35|[deal, awesome, a...|            18|\n",
      "| 63|    1|Arrived in 6 days...|[arrived, in, 6, ...|    17|[arrived, 6, days...|             7|\n",
      "+---+-----+--------------------+--------------------+------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Preparing the data:\")\n",
    "\n",
    "print(\"extract header\")\n",
    "header = reviews.first()\n",
    "\n",
    "print(\"Get columns titles\")\n",
    "columnsTitles = header.split(',')\n",
    "\n",
    "# Fill dictionary of column -> index\n",
    "columnsDict = {}\n",
    "for column in columnsTitles:\n",
    "    columnsDict[column] = columnsTitles.index(column)\n",
    "\n",
    "# Save original reviews rdd with columns titles, before filtering.\n",
    "original_reviews = reviews\n",
    "\n",
    "# Filter out headers from reviews rdd.\n",
    "reviews = reviews.filter(lambda row: row != header)\n",
    "\n",
    "# Get number of columns, based on columns titles length\n",
    "numOfColumns = len(columnsTitles)\n",
    "\n",
    "print(\"Filter out corrupted records, with invalid number of columns\")\n",
    "reviews = reviews.filter(lambda p: len(p.split(\",\")) == numOfColumns)\n",
    "\n",
    "print(\"get reviews rdd\")\n",
    "reviews_rdd = reviews.map(lambda line: line.split(\",\"))\n",
    "\n",
    "print(\"get reviews data frame\")\n",
    "reviews_df = reviews_rdd.toDF(columnsTitles)\n",
    "\n",
    "\n",
    "displaySubTitle(\"Tokenization\")\n",
    "\n",
    "# define tokenizer, with words pattern\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# define tokens counter.\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "# Tokenize reviews_df\n",
    "regexTokenized = regexTokenizer.transform(reviews_df)\n",
    "\n",
    "# Select the tokenized Text column\n",
    "tokenizedData = regexTokenized.select(\"Id\", \"Score\", \"Text\", \"words\").withColumn(\"tokens\", countTokens(col(\"words\")))\n",
    "\n",
    "print(\"Stop word removal:\\n\")\n",
    "\n",
    "print(\"Get list of stop words to be removed, using StopWordsRemover\")\n",
    "listOfWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "print(\"Define remover, with the list of stop words that have been loaded\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=listOfWords)\n",
    "\n",
    "print(\"Remove stop words\")\n",
    "filteredData = remover.transform(tokenizedData)\n",
    "\n",
    "print(\"Add count_filtered column & cast Score column from Double to Integer\")\n",
    "filteredData = filteredData.withColumn(\"count_filtered\", countTokens(col(\"filtered\"))) \\\n",
    "                    .withColumn(\"Score\", filteredData[\"Score\"].cast(IntegerType()))\n",
    "\n",
    "print(\"Display results, after removing stop words\")\n",
    "print(\"Every row's results will be displayed in the following format: Id|Score||Text|words|tokens|filtered|\")\n",
    "filteredData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------\n",
      "Task 1\n",
      "------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task1.a\n",
      "-------\n",
      "\n",
      "\n",
      "Get avarage length of review (and more statistical data):\n",
      "\n",
      "Avarage number of words in review, before words removal & tokenization: 42.27881088173079 words.\n",
      "Avarage number of words in review, after stop words removal & tokenization: 20.804328326237716 words.\n",
      "Maximum number of words in review, before words removal & tokenization: 286 words.\n",
      "Minimum number of words in review, before words removal & tokenization: 1 words.\n",
      "\n",
      "\n",
      "Task1.b\n",
      "-------\n",
      "\n",
      "\n",
      "We should use Text column, in order to predict score column\n",
      "\n",
      "\n",
      "Task1.c\n",
      "-------\n",
      "\n",
      "\n",
      "Check if there is missing data:\n",
      "In the input data set there is no missing data.\n",
      "\n",
      "\n",
      "Task1.d\n",
      "-------\n",
      "\n",
      "\n",
      "Check exceptions in reviews:\n",
      "In oredr to understand the exceptional lengths in the reviews, we will display a histograms of reviews length, before and after cleaning the data\n",
      "\n",
      "\n",
      "Histogram of reviews length before cleaning the data\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------\n",
      "Analyze tokens column\n",
      "---------------------\n",
      "\n",
      "\n",
      "\n",
      "top 10 original review lengths with maximum number of reviews:\n",
      "+----------------------+-----+\n",
      "|original review length|count|\n",
      "+----------------------+-----+\n",
      "|                    22| 5496|\n",
      "|                    24| 5120|\n",
      "|                    21| 5099|\n",
      "|                    25| 5085|\n",
      "|                    23| 5076|\n",
      "|                    26| 4747|\n",
      "|                    27| 4698|\n",
      "|                    20| 4434|\n",
      "|                    28| 4134|\n",
      "|                    30| 4039|\n",
      "+----------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      " 10 original review lengths with minimum number of reviews:\n",
      "+----------------------+-----+\n",
      "|original review length|count|\n",
      "+----------------------+-----+\n",
      "|                   259|    1|\n",
      "|                   367|    1|\n",
      "|                   233|    1|\n",
      "|                   333|    1|\n",
      "|                   285|    1|\n",
      "|                   253|    1|\n",
      "|                   322|    1|\n",
      "|                   388|    1|\n",
      "|                   321|    1|\n",
      "|                   375|    1|\n",
      "+----------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Histogram of reviews length after cleaning the data\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "Analyze count_filtered column\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "\n",
      "top 10 filtered review lengths with maximum number of reviews:\n",
      "+----------------------+-----+\n",
      "|filtered review length|count|\n",
      "+----------------------+-----+\n",
      "|                    12| 9397|\n",
      "|                    13| 9147|\n",
      "|                    14| 8890|\n",
      "|                    11| 8559|\n",
      "|                    15| 8120|\n",
      "|                    16| 7611|\n",
      "|                    10| 7380|\n",
      "|                    17| 6685|\n",
      "|                    18| 6304|\n",
      "|                     9| 5426|\n",
      "+----------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      " 10 filtered review lengths with minimum number of reviews:\n",
      "+----------------------+-----+\n",
      "|filtered review length|count|\n",
      "+----------------------+-----+\n",
      "|                   194|    1|\n",
      "|                   231|    1|\n",
      "|                   136|    1|\n",
      "|                   142|    1|\n",
      "|                   164|    1|\n",
      "|                   286|    1|\n",
      "|                   220|    1|\n",
      "|                   128|    1|\n",
      "|                   132|    1|\n",
      "|                   192|    1|\n",
      "+----------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In addition to histograms display, we will explore exceptional length, using the magic_percentile method.\n",
      "Scores grouped by percentiles review length:\n",
      "+-----+--------------------------------------+\n",
      "|score|review length magic percentiles values|\n",
      "+-----+--------------------------------------+\n",
      "|5    |[35, 17, 10, 7, 5, 1, 1]              |\n",
      "|4    |[38, 17, 10, 7, 5, 4, 4]              |\n",
      "|3    |[41, 18, 10, 6, 5, 3, 3]              |\n",
      "|2    |[41, 18, 10, 7, 4, 4, 4]              |\n",
      "|1    |[40, 19, 10, 7, 5, 1, 1]              |\n",
      "+-----+--------------------------------------+\n",
      "\n",
      "Short review frequencies found.\n",
      "Short reviews occuur in the data set at a frequency of '0.0001'\n",
      "Short Review lengths to be filtered (ordered by index of the suitable score)\n",
      "[1, 4, 3, 4, 1]\n",
      "Filter out short reviews\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task 1\")\n",
    "\n",
    "displaySubTitle(\"Task1.a\")\n",
    "print(\"Get avarage length of review (and more statistical data):\\n\")\n",
    "\n",
    "mean_words_len = filteredData.agg(F.mean(\"tokens\"))\n",
    "mean_filtered_words_len = filteredData.agg(F.mean(\"count_filtered\"))\n",
    "\n",
    "print(\"Avarage number of words in review, before words removal & tokenization: \" + repr(mean_words_len.head()[0]) + \" words.\")\n",
    "print(\"Avarage number of words in review, after stop words removal & tokenization: \" + repr(mean_filtered_words_len.head()[0]) + \" words.\")\n",
    "\n",
    "max_words_len = filteredData.agg(F.max(\"count_filtered\"))\n",
    "min_words_len = filteredData.agg(F.min(\"count_filtered\"))\n",
    "print(\"Maximum number of words in review, before words removal & tokenization: \" + repr(max_words_len.head()[0]) + \" words.\")\n",
    "print(\"Minimum number of words in review, before words removal & tokenization: \" + repr(min_words_len.head()[0]) + \" words.\")\n",
    "\n",
    "\n",
    "displaySubTitle(\"Task1.b\")\n",
    "print(\"We should use Text column, in order to predict score column\")\n",
    "\n",
    "\n",
    "displaySubTitle(\"Task1.c\")\n",
    "print(\"Check if there is missing data:\")\n",
    "\n",
    "missing_text_count = reviews_df.filter((reviews_df[\"Text\"] == \"\") | reviews_df[\"Text\"].isNull() | F.isnan(reviews_df[\"Text\"])).count()\n",
    "\n",
    "if missing_text_count == 0 :\n",
    "    print(\"In the input data set there is no missing data.\")\n",
    "else:\n",
    "    print(\"There are \" + repr(missing_text_count) + \" reviews with missing text\")\n",
    "    \n",
    "displaySubTitle(\"Task1.d\")\n",
    "print(\"Check exceptions in reviews:\")\n",
    "\n",
    "print(\"In oredr to understand the exceptional lengths in the reviews, we will display a histograms of reviews length, before and after cleaning the data\")\n",
    "\n",
    "displaySubTitle(\"Histogram of reviews length before cleaning the data\")\n",
    "analyzeColumn(filteredData, \"tokens\", \"original review length\", 'review', 1)\n",
    "displaySubTitle(\"Histogram of reviews length after cleaning the data\")\n",
    "analyzeColumn(filteredData, \"count_filtered\", \"filtered review length\", 'review', 1)\n",
    "\n",
    "\n",
    "print(\"In addition to histograms display, we will explore exceptional length, using the magic_percentile method.\")\n",
    "\n",
    "print(\"Scores grouped by percentiles review length:\")\n",
    "grp_window = Window.partitionBy('score')\n",
    "magic_percentiles_values = '0.9, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001'\n",
    "magic_percentile_alias = 'review length magic percentiles values'\n",
    "magic_percentile = F.expr('percentile_approx(count_filtered, array(' + magic_percentiles_values + '))')\n",
    "magic_percentile_score_reviews_length_df = filteredData.groupBy('score').agg(magic_percentile.alias(magic_percentile_alias)).orderBy(\"score\", ascending=False)\n",
    "magic_percentile_score_reviews_length_df.show(truncate = False)\n",
    "\n",
    "magic_percentiles = [row[0] for row in magic_percentile_score_reviews_length_df.select(magic_percentile_alias).collect()]\n",
    "m = len(magic_percentiles)\n",
    "n = len(magic_percentiles[0])\n",
    "is_duplicate_column = False\n",
    "\n",
    "for j in range(n - 1):\n",
    "    counter = 0\n",
    "    for i in range(m):\n",
    "        if magic_percentiles[i][j] != magic_percentiles[i][j + 1]:\n",
    "            break\n",
    "    if i == m - 1:\n",
    "        is_duplicate_column = True\n",
    "        break\n",
    "\n",
    "short_review_frequency = magic_percentiles_values.split(\", \")[j]\n",
    "if is_duplicate_column:\n",
    "    print(\"Short review frequencies found.\")\n",
    "\n",
    "print(\"Short reviews occuur in the data set at a frequency of \" + repr(short_review_frequency))\n",
    "irrelevant_review_length_list = []\n",
    "for magic_percentile in magic_percentiles:\n",
    "    irrelevant_review_length_list.append(magic_percentile[j])\n",
    "    \n",
    "print(\"Short Review lengths to be filtered (ordered by index of the suitable score)\")\n",
    "print(irrelevant_review_length_list)\n",
    "\n",
    "print(\"Filter out short reviews\")\n",
    "cleanData = filteredData.rdd.filter(lambda line: line['count_filtered'] >  irrelevant_review_length_list[int(line['Score']) - 1]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "In this section, we try to look for corellation between negative words and score column\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "We will try to find correlation between negative words in the text column and the score column\n",
      "For this purpose, we will use the StopWordsRemover mechanism, in order to filter out negative words from the filtered text (filtered, because stop words have already been removed)\n",
      "Get list of negative words\n",
      "Get list of positive words\n",
      "Define negative words remover, with the list of negative words\n",
      "We use the StopWordsRemover mechanism to filter out negative words\n",
      "Define poswitive words remover, with the list of positive words\n",
      "We use the StopWordsRemover mechanism to filter out positive words\n",
      "Remove negative words\n",
      "Remove positive words\n",
      "Display results, after removing negative & positive words\n",
      "Every row's results will be displayed in the following format: |Id|Score|Text|words|tokens|filtered|count_filtered|negative_filtered|count_negative_filtered|positive_filtered|count_positive_filtered|\n",
      "+---+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "| Id|Score|                Text|tokens|   negative_filtered|count_negative_filtered|   positive_filtered|count_positive_filtered|count_negative|count_positive|\n",
      "+---+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "|  1|    5|I have bought sev...|    48|[i, have, bought,...|                     45|[i, have, bought,...|                     39|             3|             9|\n",
      "|  2|    1|\"Product arrived ...|    32|[product, arrived...|                     31|[product, arrived...|                     32|             1|             0|\n",
      "|  4|    2|If you are lookin...|    41|[if, you, are, lo...|                     41|[if, you, are, lo...|                     38|             0|             3|\n",
      "|  9|    5|Right now I'm mos...|    27|[right, now, i, m...|                     27|[right, now, i, m...|                     25|             0|             2|\n",
      "| 10|    5|This is a very he...|    25|[this, is, a, ver...|                     25|[this, is, a, dog...|                     19|             0|             6|\n",
      "| 14|    4|good flavor! thes...|    15|[good, flavor, th...|                     15|[flavor, these, c...|                     12|             0|             3|\n",
      "| 15|    5|The Strawberry Tw...|    21|[the, strawberry,...|                     20|[the, strawberry,...|                     19|             1|             2|\n",
      "| 17|    2|I love eating the...|    42|[i, love, eating,...|                     42|[i, eating, them,...|                     37|             0|             5|\n",
      "| 18|    5|I am very satisfi...|    25|[i, am, very, sat...|                     25|[i, am, with, my,...|                     22|             0|             3|\n",
      "| 20|    5|Candy was deliver...|    29|[candy, was, deli...|                     28|[candy, was, deli...|                     27|             1|             2|\n",
      "| 23|    5|I can remember bu...|    29|[i, can, remember...|                     28|[i, can, remember...|                     26|             1|             3|\n",
      "| 24|    5|I love this candy...|    19|[i, love, this, c...|                     19|[i, this, candy, ...|                     17|             0|             2|\n",
      "| 28|    4|I was so glad Ama...|    37|[i, was, so, glad...|                     36|[i, was, so, amaz...|                     33|             1|             4|\n",
      "| 43|    5|I have McCann's O...|    34|[i, have, mccann,...|                     34|[i, have, mccann,...|                     28|             0|             6|\n",
      "| 45|    5|We really like th...|    48|[we, really, like...|                     48|[we, really, the,...|                     43|             0|             5|\n",
      "| 47|    5|Good oatmeal.  I ...|    48|[good, oatmeal, i...|                     48|[oatmeal, i, the,...|                     40|             0|             8|\n",
      "| 50|    3|This is the same ...|    37|[this, is, the, s...|                     37|[this, is, the, s...|                     34|             0|             3|\n",
      "| 54|    3|we're used to spi...|    34|[we, re, used, to...|                     33|[we, re, used, to...|                     32|             1|             2|\n",
      "| 57|    5|Deal was awesome!...|    35|[deal, was, aweso...|                     33|[deal, was, arriv...|                     31|             2|             4|\n",
      "| 63|    1|Arrived in 6 days...|    17|[arrived, in, 6, ...|                     16|[arrived, in, 6, ...|                     17|             1|             0|\n",
      "+---+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Sample 10000 records, in order to check for a possible correlation bwtween negative words and score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe plot shows that there is no correlation between negative words and score.\\nTherefore we should choose a different model for predicting score, based on text column\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayTitle(\"In this section, we try to look for corellation between negative words and score column\")\n",
    "print(\"We will try to find correlation between negative words in the text column and the score column\")\n",
    "print(\"For this purpose, we will use the StopWordsRemover mechanism, in order to filter out negative words from the filtered text (filtered, because stop words have already been removed)\")\n",
    "\n",
    "print(\"Get list of negative words\")\n",
    "negative_words_list = [row._c0 for row in negative_words_df.collect()]\n",
    "\n",
    "print(\"Get list of positive words\")\n",
    "positive_words_list = [row._c0 for row in positive_words_df.collect()]\n",
    "\n",
    "print(\"Define negative words remover, with the list of negative words\")\n",
    "print(\"We use the StopWordsRemover mechanism to filter out negative words\")\n",
    "negative_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"negative_filtered\", stopWords=negative_words_list)\n",
    "\n",
    "print(\"Define poswitive words remover, with the list of positive words\")\n",
    "print(\"We use the StopWordsRemover mechanism to filter out positive words\")\n",
    "positive_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"positive_filtered\", stopWords=positive_words_list)\n",
    "\n",
    "print(\"Remove negative words\")\n",
    "cleanDataWithoutNegativeWords = negative_remover.transform(cleanData).withColumn(\"count_negative_filtered\", countTokens(col(\"negative_filtered\")))\n",
    "\n",
    "print(\"Remove positive words\")\n",
    "cleanDataWithoutPositiveWords = positive_remover.transform(cleanDataWithoutNegativeWords).withColumn(\"count_positive_filtered\", countTokens(col(\"positive_filtered\")))\n",
    "\n",
    "cleanDataWithoutNegativeAndPositiveWords = cleanDataWithoutPositiveWords.select(\"Id\", \"Score\", \"Text\", \"tokens\", \"negative_filtered\", \"count_negative_filtered\", \"positive_filtered\", \"count_positive_filtered\") \\\n",
    "            .withColumn(\"Score\", cleanDataWithoutNegativeWords[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumn(\"count_negative\", col(\"tokens\") - col(\"count_negative_filtered\")) \\\n",
    "            .withColumn(\"count_positive\", col(\"tokens\") - col(\"count_positive_filtered\"))\n",
    "\n",
    "print(\"Display results, after removing negative & positive words\")\n",
    "print(\"Every row's results will be displayed in the following format: |Id|Score|Text|words|tokens|filtered|count_filtered|negative_filtered|count_negative_filtered|positive_filtered|count_positive_filtered|\")\n",
    "cleanDataWithoutNegativeAndPositiveWords.show()\n",
    "\n",
    "print(\"Sample \" + repr(numOfSamplingDefaultRecords) + \" records, in order to check for a possible correlation bwtween negative words and score\")\n",
    "num_of_records = cleanDataWithoutNegativeAndPositiveWords.count()\n",
    "percentage = 1 if num_of_records < numOfSamplingDefaultRecords else numOfSamplingDefaultRecords / num_of_records\n",
    "df_pandas = cleanDataWithoutNegativeAndPositiveWords.sample(False, percentage, filterWordsSeed).toPandas()\n",
    "plt.scatter(df_pandas['Score'], df_pandas['count_negative'],  lineWidth = 2.0)\n",
    "\n",
    "'''\n",
    "The plot shows that there is no correlation between negative words and score.\n",
    "Therefore we should choose a different model for predicting score, based on text column\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------\n",
      "Task1.e\n",
      "-------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Examples of cynical and bad Reviews:\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "13405 examples of bad reviews:\n",
      "+---+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "| Id|Score|                Text|tokens|   negative_filtered|count_negative_filtered|   positive_filtered|count_positive_filtered|count_negative|count_positive|\n",
      "+---+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "|  2|    1|\"Product arrived ...|    32|[product, arrived...|                     31|[product, arrived...|                     32|             1|             0|\n",
      "| 63|    1|Arrived in 6 days...|    17|[arrived, in, 6, ...|                     16|[arrived, in, 6, ...|                     17|             1|             0|\n",
      "| 76|    1|No tea flavor at ...|    19|[no, tea, flavor,...|                     18|[no, tea, flavor,...|                     17|             1|             2|\n",
      "|165|    1|Seriously this pr...|    48|[seriously, this,...|                     48|[seriously, this,...|                     44|             0|             4|\n",
      "|230|    1|This candy is not...|    47|[this, candy, is,...|                     46|[this, candy, is,...|                     45|             1|             2|\n",
      "|283|    1|\"I paid $1.79 for...|    75|[i, paid, 1, 79, ...|                     73|[i, paid, 1, 79, ...|                     72|             2|             3|\n",
      "|313|    1|I wouldn't even t...|    27|[i, wouldn, t, ev...|                     27|[i, wouldn, t, ev...|                     27|             0|             0|\n",
      "|325|    1|So we cancelled t...|    16|[so, we, cancelle...|                     15|[so, we, cancelle...|                     14|             1|             2|\n",
      "|382|    1|These condiments ...|    24|[these, condiment...|                     20|[these, condiment...|                     22|             4|             2|\n",
      "|394|    1|I haven't used th...|    32|[i, haven, t, use...|                     32|[i, haven, t, use...|                     31|             0|             1|\n",
      "|402|    1|This mix is very ...|    43|[this, mix, is, v...|                     41|[this, mix, is, p...|                     39|             2|             4|\n",
      "|539|    1|after opening num...|    25|[after, opening, ...|                     24|[after, numerous,...|                     23|             1|             2|\n",
      "|548|    1|I bought this bra...|   103|[i, bought, this,...|                     98|[i, bought, this,...|                     96|             5|             7|\n",
      "|551|    1|I ORDERED KETTLE ...|    55|[i, ordered, kett...|                     55|[i, ordered, kett...|                     53|             0|             2|\n",
      "|559|    1|\"Unless you reall...|    23|[unless, you, rea...|                     23|[unless, you, rea...|                     22|             0|             1|\n",
      "|673|    1|I am very disappo...|    53|[i, am, very, wit...|                     52|[i, am, disappoin...|                     49|             1|             4|\n",
      "|775|    1|The laddoos turne...|    20|[the, laddoos, tu...|                     18|[the, laddoos, tu...|                     20|             2|             0|\n",
      "|781|    1|This is NOT Disco...|    20|[this, is, not, d...|                     19|[this, is, not, d...|                     19|             1|             1|\n",
      "|832|    1|The US made versi...|    59|[the, us, made, v...|                     58|[the, us, made, v...|                     57|             1|             2|\n",
      "|880|    1|Refer to the pict...|    88|[refer, to, the, ...|                     84|[refer, to, the, ...|                     84|             4|             4|\n",
      "+---+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Out of the bad reviews, there are 19 examples of reviews that are probably cynical:\n",
      "+------+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "|    Id|Score|                Text|tokens|   negative_filtered|count_negative_filtered|   positive_filtered|count_positive_filtered|count_negative|count_positive|\n",
      "+------+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "|134783|    1|This bag of salt ...|   169|[this, bag, of, s...|                    167|[this, bag, of, s...|                    154|             2|            15|\n",
      "|136769|    1|I am going to tak...|   118|[i, am, going, to...|                    118|[i, am, going, to...|                    102|             0|            16|\n",
      "|152557|    1|I found this a fe...|   231|[i, found, this, ...|                    229|[i, found, this, ...|                    216|             2|            15|\n",
      "|154992|    1|\"After receiving ...|   174|[after, receiving...|                    172|[after, receiving...|                    156|             2|            18|\n",
      "|169392|    1|Once upon a time ...|   199|[once, upon, a, t...|                    197|[once, upon, a, t...|                    184|             2|            15|\n",
      "|222392|    1|I absolutely love...|   190|[i, absolutely, l...|                    188|[i, peach, tea, m...|                    167|             2|            23|\n",
      "|244592|    1|I ended up buying...|   148|[i, ended, up, bu...|                    148|[i, ended, buying...|                    132|             0|            16|\n",
      "|295030|    1|\"After receiving ...|   174|[after, receiving...|                    172|[after, receiving...|                    156|             2|            18|\n",
      "|309371|    1|I am new to buyin...|   141|[i, am, new, to, ...|                    139|[i, am, to, buyin...|                    126|             2|            15|\n",
      "|321825|    1|I will be honest....|   123|[i, will, be, hon...|                    121|[i, will, be, i, ...|                    103|             2|            20|\n",
      "|347336|    1|Whether you like ...|   181|[whether, you, li...|                    180|[whether, you, th...|                    165|             1|            16|\n",
      "|365654|    1|\"After receiving ...|   174|[after, receiving...|                    172|[after, receiving...|                    156|             2|            18|\n",
      "|373811|    1|I was really exci...|   192|[i, was, really, ...|                    190|[i, was, really, ...|                    174|             2|            18|\n",
      "|376427|    1|\"After receiving ...|   174|[after, receiving...|                    172|[after, receiving...|                    156|             2|            18|\n",
      "|396779|    1|I ordered this as...|   102|[i, ordered, this...|                    101|[i, ordered, this...|                     87|             1|            15|\n",
      "|433710|    1|I was really exci...|   192|[i, was, really, ...|                    190|[i, was, really, ...|                    174|             2|            18|\n",
      "|450934|    1|I really like the...|   141|[i, really, like,...|                    139|[i, really, the, ...|                    124|             2|            17|\n",
      "|477772|    1|I found these at ...|   134|[i, found, these,...|                    133|[i, found, these,...|                    119|             1|            15|\n",
      "|551710|    1|\"so my family was...|   242|[so, my, family, ...|                    240|[so, my, was, loo...|                    218|             2|            24|\n",
      "+------+-----+--------------------+------+--------------------+-----------------------+--------------------+-----------------------+--------------+--------------+\n",
      "\n",
      "\n",
      "\n",
      "10 random bad reviews:\n",
      "----------------------\n",
      "\n",
      "\n",
      "9318: I bought a 24 pack of this an drank almost all of them before realizing what the flavor reminded me of. It tastes like hotdog water.\n",
      "208769: I got these for emergency food rations that will last for at least a year. I try at least one<br />can of the products that I purchase and I must say that this stuff is nasty!! It tastes like<br />the plastic lining in the can. Yea I'll eat it if I'm starving but not until then. Anyone else<br />even remotely like this stuff? I'd be glad to send it back or give it to my daughter for her<br />dogs.\n",
      "238037: absolutely  ridiculous for AMAZON to allow someone to charge 175.00 and up to 200.00 for tassimo discs.  Taking advantage of amazon customers!! I thought AMAZON was about great pricing!!! shameful!!!!!\n",
      "241793: Three out of five cans of formula arrived at my home completely dented and leaking powdered formula.  The packaging was completely inadequate.  Whom ever did the packaging only stuck one sheet of broken bubble wrap and there is no way that they could have believed that it would have worked.  Now i have to figure out the return process.\n",
      "270230: These are very frustrating! Bought this huge box for some friends arriving from Mexico who love espresso. The water just can't get through this coffee! SOOOOOOO frustrating and a waste of money. Ground too finely!\n",
      "303866: Alvita  Nettle tea is lousy. It does not taste good. The tea bags have very little tea in them. Some of the tea bags were open and the contents spilled into the outer packaging. I will stick with another brand of Nettle tea. First they sent Parsley tea and I had to send that back. Don't waste your time or your money on this product.\n",
      "307217: All of them were melted and stuck to the inside of the packaging. Even tried to refrigerate some to no avail.  Freezer same outcome. Stuck very firmly to the packaging and fell apart trying to separate. Don't buy.\n",
      "317443: THIS IS THE WORST COFFEE WE HAVE EVER BOUGHT FROM YOU.WILL NEVER BUY AGAIN.IT IS SO WEEK TASTE LIKE HOT WATER I WASTED MY MONEY ON IT.I AM NOT HAPPY AT ALL.\n",
      "330150: This Item Taste Like Dirt.. I've Prob Used it 4 Times & Now It's Just Sitting in MY Freezer.. I Have A High Tolerance for Nasty Stuff.. Just Don't Really Like this Product.. Something In Grinding It Up Makes It Taste Nasty.. The Hulled Seeds Nutiva Sells Are Way Better.. If You Want Good Tasting Hemp Protein Powder It's $15/lb @ Earthshiftproducts.com  but It Taste Wayyy Better Actually Taste Good From Earthshift..\n",
      "363653: There were bugs in this product.  I've grown wheatgrass from seeds for over 15 years. You can tell when you first fill the soaking jar w/water (to rinse them). Gently shake it back and forth and the bugs float to the top.  If you bring a bug into your pantry it will lay eggs and you'll have bugs in all of you grains.  I had to throw it away.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5 random cynical reviews:\n",
      "-------------------------\n",
      "\n",
      "\n",
      "169392: Once upon a time this was such a wonderful product.<br /><br />The old Chocolate Twizzlers were much stronger in many ways. Taste yes and also in product 'behavior'.... The old product was 'tough' to pull apart... it actually had a 'snap' to it... This new 'stuff' behaves more like play-dough -- really 'squishy' and not in a good way. :)<br /><br />All I want to know is who is responsible for such a blunder and have they been fired yet? (kidding / well sorta)<br /><br />Dave<br /><br />Okay... I can't believe they (may have) actually listened!  I got a letter from Nestle back in Dec 2011 that they've reversed their changes to this great product and to look for new packages that have the tag line NOW WITH THE CLASSIC TWIST...  Well being in the middle of a home sale / purchase and all that goes along with that ... Chocolate Twizzlers weren't at the top of my priority... However now I'm going out to find a bag with the new tag line and I'll report back ASAP.  With any luck this 1 star review will be reissued as a 5 star. ... Fingers crossed.\n",
      "347336: Whether you like this candy or not depends a lot on why you are buying it.<br /><br />If you are older like me and looking for the red licorice that was once sold in Department Store Candy Counters and Candy stores by the bunch in the sixties and seventies then you will be disappointed. This is not even remotely similar to that candy.<br /><br />Until eight years ago our Mall Candy Store sold the original red licorice laces but they replaced it with the kind that tastes like Twizzlers in the form of a string. I have been looking to no avail for the original variety ever since. This order was my last hope and it seems the kind many of us grew up with simply isn't being made anymore.<br /><br />Personally I did not really care for the taste but that means nothing since I was looking for the kind they use to sell and this wasn't it.<br /><br />If anyone does know who sells the original type I wish they would tell me.\n",
      "376427: \"After receiving the package I was hoping my three cats would eat it and get healthier. Well none of them would even look at it. Not even hungry stray cats that live outside of my house would even touch it. For the fairness of all consumers that are interested in this product. I will write out the whole sentence that appears on the back of the package and what has been crossed out. \"\"Look for Ziwipeak  'Cuisine' in convenient pouches and easy-tab cans and Ziwipeak treats and supplements at leading natural pet stocklists. The Ziwkpeak 'Cuisine' range is produced in NZMAF-licensed 'PET FOOD' factory &lt;cross out begins> using ingredients derived from animals that have been passed as fit for human consumption in their raw state. &lt;Cross out ends>\"\" I do not care whatever excuse Ziwipeak may present but this non-human grade food is not what I am willing to spend extra money for health of my cats. I have wasted money and I have no way of returning it.\"\n",
      "396779: I ordered this as a Christmas gift for a New Mexican living elsewhere who loves red and green chile. What I got was something that was probably a delicious product but it was PAST the expiration date listed on the jar. I contacted them and never heard back. It was like they took my $30+ and didn't give a flying fig what I got for it. VERY disappointing. If they had done right by me I probably would have ordered regularly. I do not recommend this company. They do not appear to be honest or care about quality or customer service.\n",
      "477772: I found these at a local pet store but my cat won't play with them at all. She just stares at them like they are aliens from Mars. Some of the best things in life are free (sort of). Here's a tip to save you some money. Pull the ring off your milk container or orange just container and flip it off the counter and watch your cat go wild! My cat loves 'milk rings'. Her all time favorite toy above anything I have purchased that is an actual 'cat toy'. We have them all over the house.  Bottles of vinegar have a nice wide loop to pull off too. My kitty loves them because they fit so well under anything she can bat them under (like the furniture or the refrigerator).\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task1.e\")\n",
    "displaySubTitle(\"Examples of cynical and bad Reviews:\")\n",
    "'''\n",
    "\n",
    "Negative reviews identification strategy:\n",
    "-----------------------------------------\n",
    "It's easy - we just filter in all of the reviews with the lowest score (1).\n",
    "These reviews must be negative, because of their poor score.\n",
    "\n",
    "Cynical text identification strategy:\n",
    "-------------------------------------\n",
    "Usually, cynical review wiil have a low score small amount of negative words.\n",
    "The positive words will criticise the product, and present it in a negative way.\n",
    "Therefore, out of the reviews with bad scores,\n",
    "we filter in reviews with many positive words,\n",
    "but just a few negative words (at most).\n",
    "Hopefully, this approach will discover the cynical reviews.\n",
    "\n",
    "'''\n",
    "\n",
    "def df_sample_to_list(df, df_count, num_of_sampling_records, column1, column1Alias, column2, column2Alias):\n",
    "    percentageRecords = 1.0 if df_count < num_of_sampling_records else num_of_sampling_records / df_count\n",
    "    sample_list = [{column1Alias: x[column1], column2Alias: x[column2]} \\\n",
    "                    for x in df.sample(False, percentageRecords, sampleRecordsSeed).limit(num_of_sampling_records).collect()]\n",
    "    return sample_list\n",
    "\n",
    "def print_sample_list(sample_list, title, column1, column2):\n",
    "    displaySubTitle(repr(len(sample_list)) + \" \" + title + \":\")\n",
    "    for row in sample_list:\n",
    "        print(\"{}: {}\".format(row['id'], row['text']))\n",
    "\n",
    "badReviewsDF = cleanDataWithoutNegativeAndPositiveWords.rdd.filter(lambda line: line['Score'] ==  1).toDF()\n",
    "cynicalReviewsDF = badReviewsDF.rdd.filter(lambda line: line['count_negative'] <= maximumNumOfNegativeWords and line['count_positive'] > minimalNumOfPositiveWords).toDF()\n",
    "\n",
    "numBadReviewRecords = badReviewsDF.count()\n",
    "numCynicalReviewRecords = cynicalReviewsDF.count()\n",
    "\n",
    "print(repr(numBadReviewRecords) + \" examples of bad reviews:\")\n",
    "badReviewsDF.show()\n",
    "\n",
    "print(\"Out of the bad reviews, there are \" + repr(numCynicalReviewRecords) + \" examples of reviews that are probably cynical:\")\n",
    "cynicalReviewsDF.show()\n",
    "    \n",
    "bad_reviews_list =  df_sample_to_list(badReviewsDF, numBadReviewRecords, numOfSamplingBadRecords, 'Id', 'id', 'Text', 'text')\n",
    "print_sample_list(bad_reviews_list, 'random bad reviews', 'id', 'text')\n",
    "\n",
    "cynical_reviews_list =  df_sample_to_list(cynicalReviewsDF, numCynicalReviewRecords, numOfSamplingCynicalRecords, 'Id', 'id', 'Text', 'text')\n",
    "print_sample_list(cynical_reviews_list, 'random cynical reviews', 'id', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------\n",
      "Task2 (a+b)\n",
      "-----------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nType of model:\\n-------------\\nThere is no need to predict a binary answer (positive or negative review), since the score column is provided.\\nTherefore, the score will be predicted based on the Text.\\nIt means that this is a classification problem with 5 classes.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayTitle(\"Task2 (a+b)\")\n",
    "'''\n",
    "Type of model:\n",
    "-------------\n",
    "There is no need to predict a binary answer (positive or negative review), since the score column is provided.\n",
    "Therefore, the score will be predicted based on the Text.\n",
    "It means that this is a classification problem with 5 classes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Task3\n",
      "-----\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n3.a Evaluation method:\\nConfusion matrix - https://towardsdatascience.com/model-evaluation-techniques-for-classification-models-eac30092c38b\\n\\nThe correct classification will be determined by the Score column.\\n\\n-------------------\\n|True    |False   |\\n|Positive|Positive|\\n-------------------\\n|False   |True    |\\n|Negative|Negative|\\n-------------------\\n\\n\\nAccuarcy = (TP + TN) / (TP + TN + FP + FN)\\nPrecission = TP / (TP + FP)\\nRecall = Sensitivity = TP / (TP + FN)\\n\\nAccuarcy - how often is the model correct?\\nPrecission - When the model predicts positive results, how often is it correct?\\nRecall - When it is actually the positive result, how often does it predict correctly?\\n\\n\\nIn our case it's not a binary classification problem, but a multi-class classification problem.\\nTherefore the conusion matrix dimensions are: 5X5\\nWhere the main diaogonal is the TP values.\\n\\nAll of the column (excluding TP values) are FN\\nAll of the rows (excluding TP values) are FP\\n\\nWe have 5 classes that represents a given score: 1,2,3,4,5\\n\\nThe total number of test examples of any class,\\nwould be the sum of the corresponding row (i.e the TP+FN for that class)\\n\\nThe total number of FN's for a class,\\nis the sum of values in the corresponding row (excluding the TP)\\n\\nThe total number of FP's for a class,\\nis the sum of values in the corresponding column (excluding the TP)\\n\\nThe total number of TN's for a class,\\nis the sum of all columns and rows, exluding that class' column and row\\n\\nThe Recall, commonly called sensitivity,\\ncorespponds to the true-positive-rate of the considered class.\\n\\n\\n\\n\\n                        PREDICTED\\n         |--------------------------------------------\\nACTUAL   |   1        2        3        4        5\\n       1 | TP[1]     E[1,2]   E[1,3]   E[1,4]   E[1,5]\\n       2 | E[2,1]    TP[2]    E[2,3]   E[2,4]   E[2,5]\\n       3 | E[3,1]    E[3,2]   TP[3]    E[3,4]   E[3,5]\\n       4 | E[4,1]    E[4,2]   E[4,3]   TP[4]    E[4,5]\\n       5 | E[5,1]    E[5,2]   E[5,3]   E[5,4]   TP[5]\\n\\n\\nPrecision 1 = TP[1] / (TP[1] + E[2,1] + E[3,1] + E[4,1] + E[5,1])\\nPrecision 2 = TP[2] / (TP[2] + E[1,2] + E[3,2] + E[4,2] + E[5,2])\\nPrecision 3 = TP[3] / (TP[3] + E[1,3] + E[2,3] + E[4,3] + E[5,3])\\nPrecision 4 = TP[4] / (TP[4] + E[1,4] + E[2,4] + E[3,4] + E[5,4])\\nPrecision 5 = TP[5] / (TP[5] + E[1,5] + E[2,5] + E[3,5] + E[4,5])\\n\\n\\nRecall 1 = Sensitivity 1 = TP[1] / (TP[1] + E[1,2] + E[1,3] + E[1,4] + E[1,5])\\nRecall 2 = Sensitivity 2 = TP[2] / (TP[2] + E[2,1] + E[2,3] + E[2,4] + E[2,5])\\nRecall 3 = Sensitivity 3 = TP[3] / (TP[3] + E[3,1] + E[3,2] + E[3,3] + E[3,4])\\nRecall 4 = Sensitivity 4 = TP[4] / (TP[4] + E[4,1] + E[4,2] + E[4,3] + E[4,5])\\nRecall 5 = Sensitivity 5 = TP[5] / (TP[5] + E[5,1] + E[5,2] + E[5,3] + E[5,4])\\n\\n\\n3.b Features to be used:\\nText column\\n\\n3.c Model description:\\nA classifier that predict score (5 possible classes), based on text column (vectorized)\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displaySubTitle(\"Task3\")\n",
    "\n",
    "'''\n",
    "3.a Evaluation method:\n",
    "Confusion matrix - https://towardsdatascience.com/model-evaluation-techniques-for-classification-models-eac30092c38b\n",
    "\n",
    "The correct classification will be determined by the Score column.\n",
    "\n",
    "-------------------\n",
    "|True    |False   |\n",
    "|Positive|Positive|\n",
    "-------------------\n",
    "|False   |True    |\n",
    "|Negative|Negative|\n",
    "-------------------\n",
    "\n",
    "\n",
    "Accuarcy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precission = TP / (TP + FP)\n",
    "Recall = Sensitivity = TP / (TP + FN)\n",
    "\n",
    "Accuarcy - how often is the model correct?\n",
    "Precission - When the model predicts positive results, how often is it correct?\n",
    "Recall - When it is actually the positive result, how often does it predict correctly?\n",
    "\n",
    "\n",
    "In our case it's not a binary classification problem, but a multi-class classification problem.\n",
    "Therefore the conusion matrix dimensions are: 5X5\n",
    "Where the main diaogonal is the TP values.\n",
    "\n",
    "All of the column (excluding TP values) are FN\n",
    "All of the rows (excluding TP values) are FP\n",
    "\n",
    "We have 5 classes that represents a given score: 1,2,3,4,5\n",
    "\n",
    "The total number of test examples of any class,\n",
    "would be the sum of the corresponding row (i.e the TP+FN for that class)\n",
    "\n",
    "The total number of FN's for a class,\n",
    "is the sum of values in the corresponding row (excluding the TP)\n",
    "\n",
    "The total number of FP's for a class,\n",
    "is the sum of values in the corresponding column (excluding the TP)\n",
    "\n",
    "The total number of TN's for a class,\n",
    "is the sum of all columns and rows, exluding that class' column and row\n",
    "\n",
    "The Recall, commonly called sensitivity,\n",
    "corespponds to the true-positive-rate of the considered class.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        PREDICTED\n",
    "         |--------------------------------------------\n",
    "ACTUAL   |   1        2        3        4        5\n",
    "       1 | TP[1]     E[1,2]   E[1,3]   E[1,4]   E[1,5]\n",
    "       2 | E[2,1]    TP[2]    E[2,3]   E[2,4]   E[2,5]\n",
    "       3 | E[3,1]    E[3,2]   TP[3]    E[3,4]   E[3,5]\n",
    "       4 | E[4,1]    E[4,2]   E[4,3]   TP[4]    E[4,5]\n",
    "       5 | E[5,1]    E[5,2]   E[5,3]   E[5,4]   TP[5]\n",
    "\n",
    "\n",
    "Precision 1 = TP[1] / (TP[1] + E[2,1] + E[3,1] + E[4,1] + E[5,1])\n",
    "Precision 2 = TP[2] / (TP[2] + E[1,2] + E[3,2] + E[4,2] + E[5,2])\n",
    "Precision 3 = TP[3] / (TP[3] + E[1,3] + E[2,3] + E[4,3] + E[5,3])\n",
    "Precision 4 = TP[4] / (TP[4] + E[1,4] + E[2,4] + E[3,4] + E[5,4])\n",
    "Precision 5 = TP[5] / (TP[5] + E[1,5] + E[2,5] + E[3,5] + E[4,5])\n",
    "\n",
    "\n",
    "Recall 1 = Sensitivity 1 = TP[1] / (TP[1] + E[1,2] + E[1,3] + E[1,4] + E[1,5])\n",
    "Recall 2 = Sensitivity 2 = TP[2] / (TP[2] + E[2,1] + E[2,3] + E[2,4] + E[2,5])\n",
    "Recall 3 = Sensitivity 3 = TP[3] / (TP[3] + E[3,1] + E[3,2] + E[3,3] + E[3,4])\n",
    "Recall 4 = Sensitivity 4 = TP[4] / (TP[4] + E[4,1] + E[4,2] + E[4,3] + E[4,5])\n",
    "Recall 5 = Sensitivity 5 = TP[5] / (TP[5] + E[5,1] + E[5,2] + E[5,3] + E[5,4])\n",
    "\n",
    "\n",
    "3.b Features to be used:\n",
    "Text column\n",
    "\n",
    "3.c Model description:\n",
    "A classifier that predict score (5 possible classes), based on text column (vectorized)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task4\n",
      "-----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Vectorization of reviews\n",
      "------------------------\n",
      "\n",
      "\n",
      "Building binary hashing TF\n",
      "Binary vectors of text as features:\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Id |Score|Text                                                                                                                                                                                                                                                                   |words                                                                                                                                                                                                                                                                                                               |tokens|filtered                                                                                                                                                                                    |count_filtered|rawFeatures                                                                                                                                                                      |\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |5    |I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.|[i, have, bought, several, of, the, vitality, canned, dog, food, products, and, have, found, them, all, to, be, of, good, quality, the, product, looks, more, like, a, stew, than, a, processed, meat, and, it, smells, better, my, labrador, is, finicky, and, she, appreciates, this, product, better, than, most]|48    |[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]|23            |(1000,[47,168,173,182,303,308,330,408,483,547,638,639,653,662,757,854,908,941,955,984,993],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|2  |1    |\"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"\"Jumbo\"\".\"                                                                     |[product, arrived, labeled, as, jumbo, salted, peanuts, the, peanuts, were, actually, small, sized, unsalted, not, sure, if, this, was, an, error, or, if, the, vendor, intended, to, represent, the, product, as, jumbo]                                                                                           |32    |[product, arrived, labeled, jumbo, salted, peanuts, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]                                    |18            |(1000,[121,174,333,405,421,447,595,648,732,742,754,821,842,859,984],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                               |\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "\n",
      "Building hashing TF (non-binary)\n",
      "Vectors of text as features (non-binary):\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Id |Score|Text                                                                                                                                                                                                                                                                   |words                                                                                                                                                                                                                                                                                                               |tokens|filtered                                                                                                                                                                                    |count_filtered|rawFeatures                                                                                                                                                                      |\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |5    |I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.|[i, have, bought, several, of, the, vitality, canned, dog, food, products, and, have, found, them, all, to, be, of, good, quality, the, product, looks, more, like, a, stew, than, a, processed, meat, and, it, smells, better, my, labrador, is, finicky, and, she, appreciates, this, product, better, than, most]|48    |[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]|23            |(1000,[47,168,173,182,303,308,330,408,483,547,638,639,653,662,757,854,908,941,955,984,993],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0])|\n",
      "|2  |1    |\"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"\"Jumbo\"\".\"                                                                     |[product, arrived, labeled, as, jumbo, salted, peanuts, the, peanuts, were, actually, small, sized, unsalted, not, sure, if, this, was, an, error, or, if, the, vendor, intended, to, represent, the, product, as, jumbo]                                                                                           |32    |[product, arrived, labeled, jumbo, salted, peanuts, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]                                    |18            |(1000,[121,174,333,405,421,447,595,648,732,742,754,821,842,859,984],[1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0])                                               |\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "\n",
      "Building TF-IDF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF features:\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Id |Score|Text                                                                                                                                                                                                                                                                   |words                                                                                                                                                                                                                                                                                                               |tokens|filtered                                                                                                                                                                                    |count_filtered|rawFeatures                                                                                                                                                                      |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |5    |I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.|[i, have, bought, several, of, the, vitality, canned, dog, food, products, and, have, found, them, all, to, be, of, good, quality, the, product, looks, more, like, a, stew, than, a, processed, meat, and, it, smells, better, my, labrador, is, finicky, and, she, appreciates, this, product, better, than, most]|48    |[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]|23            |(1000,[47,168,173,182,303,308,330,408,483,547,638,639,653,662,757,854,908,941,955,984,993],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0])|(1000,[47,168,173,182,303,308,330,408,483,547,638,639,653,662,757,854,908,941,955,984,993],[4.618419876057438,1.5458333563555942,4.06952230434204,3.3309867684669494,2.5649225779639186,6.471737238284926,1.6461979088659473,2.5839004801651995,5.071471666568298,2.758059591682933,2.747870963027457,2.8412392527422092,2.5720848061526427,4.009451034932973,4.0730551833846,5.217120701140235,5.888288974981405,5.0418197135520035,2.5819509890736967,3.328560380200679,2.825191562997137])|\n",
      "|2  |1    |\"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"\"Jumbo\"\".\"                                                                     |[product, arrived, labeled, as, jumbo, salted, peanuts, the, peanuts, were, actually, small, sized, unsalted, not, sure, if, this, was, an, error, or, if, the, vendor, intended, to, represent, the, product, as, jumbo]                                                                                           |32    |[product, arrived, labeled, jumbo, salted, peanuts, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]                                    |18            |(1000,[121,174,333,405,421,447,595,648,732,742,754,821,842,859,984],[1.0,2.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0])                                               |(1000,[121,174,333,405,421,447,595,648,732,742,754,821,842,859,984],[3.3124368023207946,10.28214914630237,4.076995298805045,10.284438785934235,5.179563288833772,3.661969512803391,3.283097501241435,3.979641484924457,3.427008678742779,3.3921732406586855,3.153858728336669,3.3043825760973893,4.262559374949119,4.956657577929769,3.328560380200679])                                                                                                                                     |\n",
      "+---+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task4\")\n",
    "displaySubTitle(\"Vectorization of reviews\")\n",
    "\n",
    "print(\"Building binary hashing TF\")\n",
    "binaryHashingTF = HashingTF().setNumFeatures(tfNumOfFeatures).setInputCol(\"filtered\").setOutputCol(\"rawFeatures\").setBinary(True)\n",
    "binary_tf = binaryHashingTF.transform(cleanData)\n",
    "print(\"Binary vectors of text as features:\")\n",
    "binary_tf.show(2, truncate=False)\n",
    "\n",
    "print(\"\\n================================================================================================================\\n\")\n",
    "\n",
    "print(\"Building hashing TF (non-binary)\")\n",
    "hashingTF = HashingTF().setNumFeatures(tfNumOfFeatures).setInputCol(\"filtered\").setOutputCol(\"rawFeatures\")\n",
    "tf = hashingTF.transform(cleanData)\n",
    "print(\"Vectors of text as features (non-binary):\")\n",
    "tf.show(2, truncate=False)\n",
    "\n",
    "print(\"\\n================================================================================================================\\n\")\n",
    "\n",
    "print(\"Building TF-IDF\")\n",
    "idf = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(minDocFreq)\n",
    "idfModel = idf.fit(tf)\n",
    "tfidf = idfModel.transform(tf)\n",
    "print(\"TF-IDF features:\")\n",
    "tfidf.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task5\n",
      "-----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Splitting the data to train & test set with (0.7,0.3) ratio\n",
      "-----------------------------------------------------------\n",
      "\n",
      "\n",
      "Selecting score & feature columns\n",
      "Splitting binart tf vectors to train & test sets\n",
      "Splitting tf vectors to train & test sets\n",
      "Splitting tf-idf vectors to train & test sets\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task5\")\n",
    "displaySubTitle(\"Splitting the data to train & test set with (0.7,0.3) ratio\")\n",
    "\n",
    "print(\"Selecting score & feature columns\")\n",
    "binary_tf_labeled = binary_tf.select('Score', 'rawFeatures') \\\n",
    "            .withColumn(\"Score\", tf[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumnRenamed(\"Score\", \"label\") \\\n",
    "            .withColumnRenamed(\"rawFeatures\", \"features\")\n",
    "tf_labeled = tf.select('Score', 'rawFeatures') \\\n",
    "            .withColumn(\"Score\", tf[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumnRenamed(\"Score\", \"label\") \\\n",
    "            .withColumnRenamed(\"rawFeatures\", \"features\")\n",
    "tfidf_labeled = tfidf.select('Score', 'features') \\\n",
    "            .withColumn(\"Score\", tfidf[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumnRenamed(\"Score\", \"label\")\n",
    "\n",
    "print(\"Splitting binart tf vectors to train & test sets\")\n",
    "train_set_binary_tf, test_set_binary_tf = binary_tf_labeled.randomSplit(randomSplit, seed=dataSplitSeed)\n",
    "\n",
    "print(\"Splitting tf vectors to train & test sets\")\n",
    "train_set_tf, test_set_tf = tf_labeled.randomSplit(randomSplit, seed=dataSplitSeed)\n",
    "\n",
    "print(\"Splitting tf-idf vectors to train & test sets\")\n",
    "train_set_tfidf, test_set_tfidf = tfidf_labeled.randomSplit(randomSplit, seed=dataSplitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyData(classifier, train_set, test_set, paramGrid):\n",
    "\n",
    "    # Create 3-fold CrossValidator\n",
    "    cv = CrossValidator(estimator = nb,\n",
    "                        estimatorParamMaps = paramGrid,\n",
    "                        evaluator = MulticlassClassificationEvaluator(),\n",
    "                        numFolds = numOfFolds,\n",
    "                        parallelism = crossValidationParallelism)\n",
    "\n",
    "    # Run cross validations\n",
    "    cvModel = cv.fit(train_set)\n",
    "\n",
    "    # Predict data, based on the best model from cross-validation\n",
    "    predictions = cvModel.transform(test_set)\n",
    "    \n",
    "    # Make prediction and test accuracy\n",
    "    predictionsAndLabelsDF = predictions.select('label', 'prediction') \\\n",
    "    .withColumn(\"label\", predictions[\"label\"].cast(DoubleType()))\n",
    "\n",
    "    # Convert predictionsAndLabels to rdd format\n",
    "    if shift != 0:\n",
    "        predictionsAndLabelsDF = predictionsAndLabelsDF.withColumn(\"prediction\", predictions[\"prediction\"] + shift)\n",
    "    predictionsAndLabelsRDD = predictionsAndLabelsDF.rdd\n",
    "\n",
    "    # Instantiate metrics object\n",
    "    metrics = MulticlassMetrics(predictionsAndLabelsRDD)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluateClassifier(metrics):    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "\n",
    "    # Statistics by class\n",
    "    for label in sorted(scores):\n",
    "        print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "\n",
    "    # Weighted stats\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusionMatrix = metrics.confusionMatrix()\n",
    "    np.set_printoptions(formatter={'float': '{: 0.0f}'.format})\n",
    "    print(\"confusionMatrix:\")\n",
    "    print(confusionMatrix)\n",
    "    print(\"Confusion Matrix Values:\")\n",
    "    print(confusionMatrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task6\n",
      "-----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Run classifiers on TF vectors, and evaluate the results\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Set Naive Bayes classifier\n",
      "Set Logistic Regression classifier\n",
      "Create ParamGrid for Cross Validation of naive bayes, with TF vectors\n",
      "Create ParamGrid for Cross Validation of naive bayes, with TF-IDF vectors\n",
      "Create ParamGrid for Cross Validation, with TF vectors\n",
      "Create ParamGrid for Cross Validation, with TF-IDF vectors\n",
      "\n",
      "Run naive bayes with binary TF vectors ...\n",
      "\n",
      "Run naive bayes with TF vectors (non-binary) ...\n",
      "\n",
      "Run logistic regression with binary TF vectors ...\n",
      "\n",
      "Run logistic regression with TF vectors (non-binary) ...\n",
      "\n",
      "=========================================================================\n",
      "\n",
      "Evalute metrics of naive bayes with binary TF vectors\n",
      "Summary Stats\n",
      "Precision = 0.740008479682235\n",
      "Recall = 0.740008479682235\n",
      "Class 1 precision = 0.4969666329625885\n",
      "Class 1 recall = 0.5253874933190807\n",
      "Class 2 precision = 0.1598870056497175\n",
      "Class 2 recall = 0.34512195121951217\n",
      "Class 3 precision = 0.1708407871198569\n",
      "Class 3 recall = 0.35174953959484345\n",
      "Class 4 precision = 0.11404728789986092\n",
      "Class 4 recall = 0.39861111111111114\n",
      "Class 5 precision = 0.9415110943491105\n",
      "Class 5 recall = 0.7940888005301524\n",
      "Weighted recall = 0.740008479682235\n",
      "Weighted precision = 0.8448223441610009\n",
      "Weighted false positive rate = 0.23002375045938245\n",
      "confusionMatrix:\n",
      "DenseMatrix([[ 1966,  403,  303,  261,  809],\n",
      "             [ 188,  283,  121,  85,  143],\n",
      "             [ 125,  116,  382,  177,  286],\n",
      "             [ 39,  58,  146,  574,  623],\n",
      "             [ 1638,  910,  1284,  3936,  29957]])\n",
      "Confusion Matrix Values:\n",
      "[ 1966  188  125  39  1638  403  283  116  58  910  303  121  382  146\n",
      "  1284  261  85  177  574  3936  809  143  286  623  29957]\n",
      "\n",
      "=========================================================================\n",
      "\n",
      "Evalute metrics of naive bayes with TF vectors (non-binary)\n",
      "Summary Stats\n",
      "Precision = 0.7317296320264209\n",
      "Recall = 0.7317296320264209\n",
      "Class 1 precision = 0.5106167846309403\n",
      "Class 1 recall = 0.5032386646736422\n",
      "Class 2 precision = 0.18870056497175142\n",
      "Class 2 recall = 0.3411644535240041\n",
      "Class 3 precision = 0.18202146690518783\n",
      "Class 3 recall = 0.30693815987933637\n",
      "Class 4 precision = 0.1414663222729982\n",
      "Class 4 recall = 0.36814891416752843\n",
      "Class 5 precision = 0.921428122446414\n",
      "Class 5 recall = 0.8019146608315099\n",
      "Weighted recall = 0.7317296320264209\n",
      "Weighted precision = 0.813083750600252\n",
      "Weighted false positive rate = 0.25769236960947783\n",
      "confusionMatrix:\n",
      "DenseMatrix([[ 2020,  408,  323,  286,  977],\n",
      "             [ 230,  334,  132,  84,  199],\n",
      "             [ 159,  144,  407,  211,  405],\n",
      "             [ 56,  70,  177,  712,  919],\n",
      "             [ 1491,  814,  1197,  3740,  29318]])\n",
      "Confusion Matrix Values:\n",
      "[ 2020  230  159  56  1491  408  334  144  70  814  323  132  407  177\n",
      "  1197  286  84  211  712  3740  977  199  405  919  29318]\n",
      "\n",
      "=========================================================================\n",
      "\n",
      "Evalute metrics of logistic regression with binary TF vectors\n",
      "Summary Stats\n",
      "Precision = 0.7402762591212372\n",
      "Recall = 0.7402762591212372\n",
      "Class 1 precision = 0.4982305358948433\n",
      "Class 1 recall = 0.5274284185175274\n",
      "Class 2 precision = 0.15932203389830507\n",
      "Class 2 recall = 0.34558823529411764\n",
      "Class 3 precision = 0.17128801431127014\n",
      "Class 3 recall = 0.3559479553903346\n",
      "Class 4 precision = 0.11623286310351678\n",
      "Class 4 recall = 0.4026152787336545\n",
      "Class 5 precision = 0.9413853793450249\n",
      "Class 5 recall = 0.7938565105616072\n",
      "Weighted recall = 0.7402762591212373\n",
      "Weighted precision = 0.844944509268639\n",
      "Weighted false positive rate = 0.23071539165794858\n",
      "confusionMatrix:\n",
      "DenseMatrix([[ 1971,  398,  300,  261,  807],\n",
      "             [ 186,  282,  118,  80,  150],\n",
      "             [ 126,  114,  383,  170,  283],\n",
      "             [ 40,  60,  143,  585,  625],\n",
      "             [ 1633,  916,  1292,  3937,  29953]])\n",
      "Confusion Matrix Values:\n",
      "[ 1971  186  126  40  1633  398  282  114  60  916  300  118  383  143\n",
      "  1292  261  80  170  585  3937  807  150  283  625  29953]\n",
      "\n",
      "=========================================================================\n",
      "\n",
      "Evalute metrics of logistic regression with TF vectors (non-binary)\n",
      "Summary Stats\n",
      "Precision = 0.7313279628679178\n",
      "Recall = 0.7313279628679178\n",
      "Class 1 precision = 0.5103640040444893\n",
      "Class 1 recall = 0.5014903129657228\n",
      "Class 2 precision = 0.18361581920903955\n",
      "Class 2 recall = 0.3343621399176955\n",
      "Class 3 precision = 0.18291592128801432\n",
      "Class 3 recall = 0.30682670667666917\n",
      "Class 4 precision = 0.1412676336181204\n",
      "Class 4 recall = 0.3691588785046729\n",
      "Class 5 precision = 0.921145263687221\n",
      "Class 5 recall = 0.8017562096509465\n",
      "Weighted recall = 0.7313279628679178\n",
      "Weighted precision = 0.8127662665148455\n",
      "Weighted false positive rate = 0.2584377664120634\n",
      "confusionMatrix:\n",
      "DenseMatrix([[ 2019,  412,  323,  284,  988],\n",
      "             [ 234,  325,  131,  82,  200],\n",
      "             [ 159,  144,  409,  215,  406],\n",
      "             [ 58,  67,  175,  711,  915],\n",
      "             [ 1486,  822,  1198,  3741,  29309]])\n",
      "Confusion Matrix Values:\n",
      "[ 2019  234  159  58  1486  412  325  144  67  822  323  131  409  175\n",
      "  1198  284  82  215  711  3741  988  200  406  915  29309]\n",
      "\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task6\")\n",
    "displaySubTitle(\"Run classifiers on TF vectors, and evaluate the results\")\n",
    "\n",
    "print(\"Set Naive Bayes classifier\")\n",
    "nb = NaiveBayes(smoothing=1.0, modelType='multinomial', featuresCol='features', labelCol='label')\n",
    "\n",
    "print(\"Set Logistic Regression classifier\")\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0, labelCol = 'label')\n",
    "\n",
    "print(\"Create ParamGrid for Cross Validation of naive bayes, with TF vectors\")\n",
    "nbTfParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(nb.smoothing, smoothingGridParam)\n",
    "               .addGrid(hashingTF.numFeatures, numOfFeaturesGridParam) # Number of features\n",
    "               .build())\n",
    "\n",
    "print(\"Create ParamGrid for Cross Validation of naive bayes, with TF-IDF vectors\")\n",
    "nbTfIdfParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(nb.smoothing, smoothingGridParam)\n",
    "               .build())\n",
    "\n",
    "print(\"Create ParamGrid for Cross Validation, with TF vectors\")\n",
    "lrTfParamGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, regGridParam) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, elasticNetGridParam) # Elastic Net Parameter (Ridge = 0)\n",
    "             .addGrid(hashingTF.numFeatures, numOfFeaturesGridParam) # Number of features\n",
    "             .addGrid(lr.maxIter, maxIterGridParam) #Number of iterations\n",
    "             .build())\n",
    "\n",
    "print(\"Create ParamGrid for Cross Validation, with TF-IDF vectors\")\n",
    "lrTfIdfParamGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, regGridParam) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, elasticNetGridParam) # Elastic Net Parameter (Ridge = 0)\n",
    "             .addGrid(lr.maxIter, maxIterGridParam) #Number of iterations\n",
    "             .build())\n",
    "\n",
    "print(\"\\nRun naive bayes with binary TF vectors ...\")\n",
    "nb_binary_tf_metrics = classifyData(nb, train_set_binary_tf, test_set_binary_tf, nbTfParamGrid)\n",
    "\n",
    "print(\"\\nRun naive bayes with TF vectors (non-binary) ...\")\n",
    "nb_tf_metrics = classifyData(nb, train_set_tf, test_set_tf, nbTfParamGrid)\n",
    "\n",
    "print(\"\\nRun logistic regression with binary TF vectors ...\")\n",
    "lr_binary_tf_metrics = classifyData(lr, train_set_binary_tf, test_set_binary_tf, lrTfParamGrid)\n",
    "\n",
    "print(\"\\nRun logistic regression with TF vectors (non-binary) ...\")\n",
    "lr_tf_metrics = classifyData(lr, train_set_tf, test_set_tf, lrTfParamGrid)\n",
    "\n",
    "print(\"\\n=========================================================================\")\n",
    "print(\"\\nEvalute metrics of naive bayes with binary TF vectors\")\n",
    "evaluateClassifier(nb_binary_tf_metrics)\n",
    "print(\"\\n=========================================================================\")\n",
    "\n",
    "print(\"\\nEvalute metrics of naive bayes with TF vectors (non-binary)\")\n",
    "evaluateClassifier(nb_tf_metrics)\n",
    "print(\"\\n=========================================================================\")\n",
    "\n",
    "print(\"\\nEvalute metrics of logistic regression with binary TF vectors\")\n",
    "evaluateClassifier(lr_binary_tf_metrics)\n",
    "print(\"\\n=========================================================================\")\n",
    "\n",
    "print(\"\\nEvalute metrics of logistic regression with TF vectors (non-binary)\")\n",
    "evaluateClassifier(lr_tf_metrics)\n",
    "print(\"\\n=========================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTitle(\"Task8\")\n",
    "displaySubTitle(\"Run classifiers on TF-IDF vectors, and evaluate the results\")\n",
    "\n",
    "print(\"\\nRun naive bayes with TF-IDF vectors ...\")\n",
    "nb_tf_metrics = classifyData(nb, nb_shift, train_set_tfidf, test_set_tfidf, nbTfIdfParamGrid)\n",
    "\n",
    "print(\"\\nRun logistic regression with TF-IDF vectors ...\")\n",
    "lr_tf_metrics = classifyData(lr, lr_shift, train_set_tfidf, test_set_tfidf, lrTfIdfParamGrid)\n",
    "\n",
    "print(\"\\n=========================================================================\")\n",
    "print(\"\\nEvalute metrics of naive bayes with TF-IDF vectors\")\n",
    "evaluateClassifier(nb_tf_metrics)\n",
    "print(\"\\n=========================================================================\")\n",
    "\n",
    "print(\"Evalute metrics of logistic regression with TF-IDF vectors\")\n",
    "evaluateClassifier(lr_tf_metrics)\n",
    "print(\"\\n=========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTitle(\"Task7\")\n",
    "displaySubTitle(\"Clustering the data\")\n",
    "\n",
    "'''\n",
    "We will use k-means with k=2 clusters,\n",
    "and try to find correlation between one cluster and negative reviews,\n",
    "and a correlation between the second cluster and positive reviews.\n",
    "'''\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "kmeansModel = kmeans.fit(train_set_tf)\n",
    "\n",
    "# Make predictions\n",
    "kmeansPredictions = kmeansModel.transform(test_set_tf)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(kmeansPredictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "# Shows the clusters.\n",
    "centers = kmeansModel.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "# Split the predictions data into 2 dataframes, based on the suitable cluster (0/1)\n",
    "clusters_df = kmeansPredictions.select('label', 'prediction')\n",
    "cluster_0_df = clusters_df.filter('prediction == 0')\n",
    "cluster_1_df = clusters_df.filter('prediction == 1')\n",
    "\n",
    "# Sample the 2 splitted dataframes and convert them to pandas data frame\n",
    "print(\"Sample \" + repr(numOfSamplingDefaultRecords) + \" records, in order to check for a possible correlation between cluster_0 and the given scores\")\n",
    "num_of_cluster0_records = cluster_0_df.count()\n",
    "cluster0_percentage = 1.0 if num_of_cluster0_records < numOfSamplingDefaultRecords else numOfSamplingDefaultRecords / num_of_cluster0_records\n",
    "df_cluster0_pandas = cluster_0_df.sample(False, cluster0_percentage, clusterSeed).toPandas()\n",
    "num_of_cluster1_records = cluster_1_df.count()\n",
    "cluster1_percentage = 1.0 if num_of_cluster1_records < numOfSamplingDefaultRecords else numOfSamplingDefaultRecords / num_of_cluster1_records\n",
    "df_cluster1_pandas = cluster_1_df.sample(False, cluster1_percentage, clusterSeed).toPandas()\n",
    "\n",
    "# Plot 2 histograms of score & score count, corresponding to the 2 splitted dataframes.\n",
    "fig, (left_plt, right_plt) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "left_plt.hist(df_cluster0_pandas['label'],\n",
    "         bins=scores,\n",
    "         density=False,\n",
    "         histtype='bar',\n",
    "         color='b',\n",
    "         edgecolor='k',\n",
    "         alpha=0.5)\n",
    "left_plt.set_title(\"cluster_0\")\n",
    "\n",
    "right_plt.hist(df_cluster1_pandas['label'],\n",
    "         bins=scores,\n",
    "         density=False,\n",
    "         histtype='bar',\n",
    "         color='b',\n",
    "         edgecolor='k',\n",
    "         alpha=0.5)\n",
    "right_plt.set_title(\"cluster_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTitle(\"Task9\")\n",
    "displaySubTitle(\"Comparing the clustering results with the classification results\")\n",
    "'''\n",
    "From the histograms in task 8 we can conclude that there is no correlation between clusters and scores.\n",
    "Therefore negative/positive reviews should not be classified based on these 2 clusters\n",
    "\n",
    "on the other hand converting 5 score classes,\n",
    "into 2 classes (negative/positive reviews) is straight forward.\n",
    "Score 5 is classified as positive review\n",
    "Score 4 is classified as positive review\n",
    "Score 1 is classified as negative review\n",
    "Score 2 is classified as negative review\n",
    "Score 3 is classified as negative review (For the balance, since most of the scores are 5)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
