{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import lit, col, udf\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.types import ArrayType, IntegerType, DoubleType, StringType\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import numpy as np\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, MultilabelMetrics\n",
    "from pyspark.sql import Window, Row\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================\n",
    "#Common variables:\n",
    "#=================\n",
    "\n",
    "# Columns configuration:\n",
    "#-----------------------\n",
    "textColumn = \"Summary\"\n",
    "textColumnTitle = textColumn.lower()\n",
    "fullTextColumn = \"Text\"\n",
    "fullTextColumnTitle = fullTextColumn.lower()\n",
    "\n",
    "# Display records configuration:\n",
    "#-------------------------------\n",
    "numOfTopRecords = 10 # Default number of top records to display\n",
    "maxNumOfTopRecords = 20 # Maxmum number of top records to display\n",
    "minNumOfTopRecords = 2 # Minimum number of top records to display\n",
    "\n",
    "# Cynical words configuration\n",
    "#-----------------------------\n",
    "minimalNumOfPositiveWords = 10 # The minimum number of positive words to filter in,for considering a word as cynical\n",
    "maximumNumOfNegativeWords = 3 # The maximun number of negative words to filter in, for considering a word as cynical\n",
    "\n",
    "# Histogram configuration\n",
    "#------------------------\n",
    "numOfBinsInHistogramOfContinueosValues = 100 # visualization property: number of bins to display in coninueous values histogram\n",
    "\n",
    "\n",
    "# Classifiers configuration:\n",
    "#---------------------------\n",
    "shift = 1 # classification algorithms will name the class, by the index. But the minimal score is 1, so the indices should be shifted by 1 unit.\n",
    "scores = [1,2,3,4,5] # Possible scores - these are the labels of the classifiers.\n",
    "randomSplit = [0.7, 0.3] # The split ration of the dataset. First element for traning set, and second element for test set.\n",
    "\n",
    "# Sampling records configuration:\n",
    "#--------------------------------\n",
    "numOfSamplingDefaultRecords = 10000 # Number of records than can be collected from data frames in the driver\n",
    "numOfSamplingBadRecords = 10 # NUmber of collected bad records to display\n",
    "numOfSamplingCynicalRecords = 6 # NUmber of collected cynical records to display\n",
    "\n",
    "# TF & TF-IDF configuration:\n",
    "#---------------------------\n",
    "tfNumOfFeatures = 10000 # Default number of features in TF-IDF vectors\n",
    "minDocFreq = 6 # Minimum number of documents frequencies, which is the nuber of occurences of terms in documents\n",
    "\n",
    "# Grid param (cross validation) configuration:\n",
    "#---------------------------------------------\n",
    "numOfFolds = 3 # Number of folds in cross validation\n",
    "smoothingGridParam = [0.1, 0.5, 1.0] # Smoothing parameter for naive bayes classifier\n",
    "numOfFeaturesGridParam = [1000, 5000, 10000] # Number of features in classifier\n",
    "maxIterGridParam = [10, 20, 50] # Maximum number of iterations in clssifier optimization algorithm\n",
    "crossValidationParallelism = 8 # Number of executors that should run cross validation in parallel (In case of single machine configuration - it will be effectively, the number of C.P.U cores)\n",
    "\n",
    "# Seed configuration:\n",
    "#--------------------\n",
    "filterWordsSeed = 41\n",
    "dataSplitSeed = 1234\n",
    "clusterSeed = 42\n",
    "sampleRecordsSeed = 47\n",
    "\n",
    "\n",
    "#=================\n",
    "#Common functions:\n",
    "#=================\n",
    "\n",
    "# Display the dash character ('-') for a given length times\n",
    "def displayMultipleDashes(title, length):\n",
    "    print('-' * length)\n",
    "\n",
    "# Display title, with dash decoration\n",
    "def displayTitle(title):\n",
    "    length = len(title)\n",
    "    print(\"\\n\")\n",
    "    displayMultipleDashes(title, length)\n",
    "    print(title)\n",
    "    displayMultipleDashes(title, length)\n",
    "    \n",
    "# Display title, with dash decoration\n",
    "def displaySubTitle(title):\n",
    "    length = len(title)\n",
    "    print(\"\\n\")\n",
    "    print(title)\n",
    "    displayMultipleDashes(title, length)\n",
    "    \n",
    "\n",
    "#===================\n",
    "#Histogram functions:\n",
    "#===================\n",
    "    \n",
    "# Get aggregated data frame of a given column, and the suitable count.\n",
    "# Parameters:\n",
    "# df - data frame\n",
    "# columnName - name of column to aggregate\n",
    "# columnAlias - alternative name of the columnName\n",
    "# Returns:\n",
    "# aggregated data frame, with 2 columns: alias column, and the suitable count frequiencies column.\n",
    "def getAggregatedDfCount(df, columnName, columnAlias):\n",
    "    return df.groupBy(columnName).agg(F.size(F.collect_list(columnName))).select(col(columnName).alias(columnAlias), col(\"size(collect_list(\" + columnName + \"))\").alias(\"count\"))\n",
    "\n",
    "# Analyze column which contains continueous values, and display a histogram.\n",
    "# aggregated_df - data frame with 2 columns: column and column count.\n",
    "# pandas_df - aggregated_df converted to pandas dataframe.\n",
    "# columnName - name of column to analyze, in aggregated_df\n",
    "# columnAlias - name of column to analyze, in columnAlias\n",
    "# recordName - name of record, which represents the original rows in aggregated_df\n",
    "# numOfBins - number of bins to display in the histogram\n",
    "def analyzeContinuousValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, numOfBins):\n",
    "    \n",
    "    # Show top records with highest frequencies.\n",
    "    print(\"\\ntop \" + repr(numOfTopRecords) + \" \" + columnAlias + \"s with maximum number of \" + recordName + \"s:\")\n",
    "    aggregated_df.orderBy(\"count\", ascending=False).show(numOfTopRecords)\n",
    "    \n",
    "    # Show top records with lowest frequencies.\n",
    "    print(\"\\n \" + repr(numOfTopRecords) + \" \" + columnAlias + \"s with minimum number of \" + recordName + \"s:\")\n",
    "    aggregated_df.orderBy(\"count\").show(numOfTopRecords)\n",
    "\n",
    "    # Create histogram plot.\n",
    "    pandas_df.plot.hist(grid=True, bins=numOfBins, rwidth=1, color='#607c8e')\n",
    "    plt.title('Products reviews')\n",
    "    plt.xlabel(\"#\" + recordName + \"s\")\n",
    "    plt.ylabel(columnAlias + \"s\")\n",
    "    plt.title(\"Histogram of number of \" + recordName + \"s per \" + columnAlias)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    \n",
    "    # Plot histogram.\n",
    "    plt.show()\n",
    "    \n",
    "# Analyze column which contains descrete values, and display a bar graph.\n",
    "# aggregated_df - data frame with 2 columns: column and column count.\n",
    "# pandas_df - aggregated_df converted to pandas dataframe.\n",
    "# columnName - name of column to analyze, in aggregated_df\n",
    "# columnAlias - name of column to analyze, in columnAlias\n",
    "# recordName - name of record, which represents the original rows in aggregated_df\n",
    "# numOfBins - number of bins to display in the bar graph\n",
    "def analyzeDescreteValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, numOfBins):   \n",
    "    # Force convertion of alias column to int type, if conversion fails - don't throw erroes\n",
    "    pandas_df[columnAlias] = pd.to_numeric(pandas_df[columnAlias], errors='coerce').astype(int)\n",
    "    \n",
    "    # Sort alias column in descending order.\n",
    "    pandas_df.sort_values(by=[columnAlias], inplace=True)\n",
    "    \n",
    "    # Remove index column (for diaplay purposes)\n",
    "    blankIndex=[''] * len(pandas_df)\n",
    "    pandas_df.index=blankIndex\n",
    "    \n",
    "    # Display frequncies of alias column.\n",
    "    display(pandas_df.nlargest(numOfBins,columns=columnAlias))\n",
    "    \n",
    "    # Create bar plot\n",
    "    pandas_df.plot(kind='bar',x=columnAlias,y='count')\n",
    "    \n",
    "    # Plot bar graph\n",
    "    plt.show()\n",
    "\n",
    "# Analyze column values frequencies, and plot the results.\n",
    "# Parameters:\n",
    "# df - dataframe\n",
    "# columnName - name of column in df to analyze\n",
    "# columnAlias - alternative name of the columnName. Will be used for display purposes.\n",
    "# recordName - name of record, which represents the original rows in df\n",
    "# columnType - 0 - for descrete values, 1 - for continuous values\n",
    "def analyzeColumn(df, columnName, columnAlias, recordName, columnType):\n",
    "    displayTitle(\"Analyze \" +  columnName + \" column\")\n",
    "    \n",
    "    # group df by columnName as columnAlias.\n",
    "    aggregated_df = getAggregatedDfCount(df, columnName, columnAlias)\n",
    "    \n",
    "    # Convert df to pandas data frame.\n",
    "    pandas_df = aggregated_df.toPandas()\n",
    "    \n",
    "    # Check if current column contains descrere values or continueous values \n",
    "    if columnType == 0: # descrete values column\n",
    "        #  analyze descrete column & plot bar graph\n",
    "        analyzeDescreteValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, columnCountDict[columnName])\n",
    "    else: # columnType == 1 ==> continuous values column\n",
    "        #  analyze continuous column & plot histogram\n",
    "        analyzeContinuousValueColumn(aggregated_df, pandas_df, columnName, columnAlias, recordName, numOfBinsInHistogramOfContinueosValues)\n",
    "    \n",
    "    # Release unused memory\n",
    "    del pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------\n",
      "Loading the data:\n",
      "-----------------\n",
      "\n",
      "\n",
      "Make sure that data files are not missing\n",
      "-----------------------------------------\n",
      "Validation pased: All of the data files are not missing\n",
      "\n",
      "\n",
      "Read data files\n",
      "---------------\n",
      "Load the dat set from: Reviews.csv\n",
      "Load negative words from: negative-words.txt\n",
      "Load positive words from: positive-words.txt\n",
      "\n",
      "Data has been successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Loading the data:\")\n",
    "dataset_file = \"Reviews.csv\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "\n",
    "displaySubTitle(\"Make sure that data files are not missing\")\n",
    "\n",
    "# Raise an error, if dataset does not exist\n",
    "# The dataset can be downloaded from this url: https://www.kaggle.com/qwikfix/amazon-recommendation-dataset/data\n",
    "# The expected path of the dataset, should be in the same directory of this jupyter notebook file.\n",
    "if not os.path.exists(dataset_file):\n",
    "    raise ValueError('Dataset file %s does not exist' % dataset_file)\n",
    "    \n",
    "# Raise an error, if negative words file does not exist\n",
    "if not os.path.exists(negative_words_file):\n",
    "    raise ValueError('negative words file %s does not exist' % negative_words_file)\n",
    "    \n",
    "# Raise an error, if positive words file does not exist\n",
    "if not os.path.exists(positive_words_file):\n",
    "    raise ValueError('positive words file %s does not exist' % positive_words_file)\n",
    "\n",
    "print(\"Validation pased: All of the data files are not missing\")\n",
    "    \n",
    "displaySubTitle(\"Read data files\")\n",
    "    \n",
    "print(\"Load the dat set from: \" + dataset_file)\n",
    "reviews = sc.textFile(dataset_file)\n",
    "\n",
    "print(\"Load negative words from: \" + negative_words_file)\n",
    "negative_words = [line.rstrip('\\n') for line in open(negative_words_file)]\n",
    "\n",
    "print(\"Load positive words from: \" + positive_words_file)\n",
    "positive_words = [line.rstrip('\\n') for line in open(positive_words_file)]\n",
    "\n",
    "print(\"\\nData has been successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------\n",
      "Preparing the data:\n",
      "-------------------\n",
      "\n",
      "\n",
      "Removing unwanted characters\n",
      "----------------------------\n",
      "Extract header\n",
      "Get columns titles\n",
      "Filter out headers from reviews rdd\n",
      "Get number of columns, based on columns titles length\n",
      "Filter out corrupted records, with invalid number of columns\n",
      "get reviews rdd\n",
      "get reviews data frame, and remove records with empty summary or text columns\n",
      "Define UDF's for colums operations:\n",
      "Remove puctuations from Summary column & convert the text to lower case\n",
      "\n",
      "\n",
      "Tokenization\n",
      "------------\n",
      "define tokenizer, with words pattern\n",
      "Tokenize reviews_df\n",
      "Select only the relevant columns from the tokenized data\n",
      "Select the columns: ['id', 'Score', 'Summary', 'Text', 'summaryWords', 'textWords'] and count tokens of Summary column\n",
      "\n",
      "\n",
      "Stop word removal:\n",
      "------------------\n",
      "Get list of stop words to be removed, using StopWordsRemover\n",
      "Define remover, with the list of stop words that have been loaded\n",
      "Remove stop words\n",
      "Add count_filtered column & cast Score column from Double to Integer & filter empty filtered reviews\n",
      "Display results, after removing stop words\n",
      "+---+-----+---------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+--------------+--------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+-----------------+\n",
      "|id |Score|Summary              |Text                                                                                                                                                                                                                                                                |summaryWords              |textWords                                                                                                                                                                                                                                                                                                           |countSummaryWords|countTextWords|summaryFiltered           |textFiltered                                                                                                                                                                                |countSummaryFiltered|countTextFiltered|\n",
      "+---+-----+---------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+--------------+--------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+-----------------+\n",
      "|1  |5    |good quality dog food|i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most|[good, quality, dog, food]|[i, have, bought, several, of, the, vitality, canned, dog, food, products, and, have, found, them, all, to, be, of, good, quality, the, product, looks, more, like, a, stew, than, a, processed, meat, and, it, smells, better, my, labrador, is, finicky, and, she, appreciates, this, product, better, than, most]|4                |48            |[good, quality, dog, food]|[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]|4                   |23               |\n",
      "|2  |1    |not as advertised    |product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo                                                                             |[not, as, advertised]     |[product, arrived, labeled, as, jumbo, salted, peanutsthe, peanuts, were, actually, small, sized, unsalted, not, sure, if, this, was, an, error, or, if, the, vendor, intended, to, represent, the, product, as, jumbo]                                                                                             |3                |31            |[advertised]              |[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]                                 |1                   |18               |\n",
      "+---+-----+---------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+--------------+--------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove html tags from text\n",
    "def cleanHtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "# Remove punctuation from text\n",
    "def cleanPunctuation(x):\n",
    "  punc='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "  lowercased_str = x.lower()\n",
    "  for ch in punc:\n",
    "    lowercased_str = lowercased_str.replace(ch, '')\n",
    "  return lowercased_str\n",
    "\n",
    "displayTitle(\"Preparing the data:\")\n",
    "\n",
    "displaySubTitle(\"Removing unwanted characters\")\n",
    "\n",
    "print(\"Extract header\")\n",
    "header = reviews.first()\n",
    "\n",
    "print(\"Get columns titles\")\n",
    "columnsTitles = header.split(',')\n",
    "\n",
    "print(\"Filter out headers from reviews rdd\")\n",
    "reviews = reviews.filter(lambda row: row != header)\n",
    "\n",
    "print(\"Get number of columns, based on columns titles length\")\n",
    "numOfColumns = len(columnsTitles)\n",
    "\n",
    "print(\"Filter out corrupted records, with invalid number of columns\")\n",
    "reviews = reviews.filter(lambda p: len(p.split(\",\")) == numOfColumns)\n",
    "\n",
    "print(\"get reviews rdd\")\n",
    "reviews_rdd = reviews.map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Release unused memory\n",
    "del reviews\n",
    "\n",
    "print(\"get reviews data frame, and remove records with empty summary or text columns\")\n",
    "reviews_df = reviews_rdd.toDF(columnsTitles).filter(\"Text != '' and Summary != ''\")\n",
    "\n",
    "print(\"Define UDF's for colums operations:\")\n",
    "# Define Punctuation text stripper\n",
    "udfFunc_CleanPunctuation = udf(cleanPunctuation, StringType())\n",
    "# Define html tags text stripper\n",
    "udfFunc_CleanHtml = udf(cleanHtml, StringType())\n",
    "# Define tokens counter\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "print(\"Remove puctuations from \" + textColumn + \" column & convert the text to lower case\")\n",
    "reviews_df = reviews_df.withColumn('Summary',udfFunc_CleanPunctuation(reviews_df['Summary'])) \\\n",
    "                       .withColumn('Text',udfFunc_CleanPunctuation(udfFunc_CleanHtml(reviews_df['Text'])))\n",
    "\n",
    "displaySubTitle(\"Tokenization\")\n",
    "\n",
    "print(\"define tokenizer, with words pattern\")\n",
    "summaryTokenizer = RegexTokenizer(inputCol=\"Summary\", outputCol=\"summaryWords\", pattern=\"\\\\W\")\n",
    "textTokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"textWords\", pattern=\"\\\\W\")\n",
    "\n",
    "print(\"Tokenize reviews_df\")\n",
    "summaryTokenized = summaryTokenizer.transform(reviews_df)\n",
    "\n",
    "textAndSummaryTokenized = textTokenizer.transform(summaryTokenized)\n",
    "\n",
    "# Release unused memory\n",
    "del summaryTokenized\n",
    "\n",
    "print(\"Select only the relevant columns from the tokenized data\")\n",
    "selectColumns = [\"id\", \"Score\", \"Summary\", \"Text\", \"summaryWords\", \"textWords\"]\n",
    "\n",
    "print(\"Select the columns: \" + str(selectColumns) + \" and count tokens of \" + textColumn + \" column\")\n",
    "tokenizedData = textAndSummaryTokenized.select(selectColumns) \\\n",
    "                .withColumn(\"countSummaryWords\", countTokens(col(\"summaryWords\"))) \\\n",
    "                .withColumn(\"countTextWords\", countTokens(col(\"textWords\")))\n",
    "\n",
    "# Release unused memory\n",
    "del textAndSummaryTokenized\n",
    "\n",
    "displaySubTitle(\"Stop word removal:\")\n",
    "\n",
    "print(\"Get list of stop words to be removed, using StopWordsRemover\")\n",
    "listOfWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "print(\"Define remover, with the list of stop words that have been loaded\")\n",
    "summaryStopWordsRemover = StopWordsRemover(inputCol=\"summaryWords\", outputCol=\"summaryFiltered\", stopWords=listOfWords)\n",
    "textStopWordsRemover = StopWordsRemover(inputCol=\"textWords\", outputCol=\"textFiltered\", stopWords=listOfWords)\n",
    "\n",
    "print(\"Remove stop words\")\n",
    "summaryFilteredData = summaryStopWordsRemover.transform(tokenizedData).where(F.length(col(\"Summary\")) > 0)\n",
    "\n",
    "# Release unused memory\n",
    "del tokenizedData\n",
    "\n",
    "summaryAndTextFilteredData = textStopWordsRemover.transform(summaryFilteredData).where(F.length(col(\"Text\")) > 0)\n",
    "\n",
    "# Release unused memory\n",
    "del summaryFilteredData\n",
    "\n",
    "print(\"Add count_filtered column & cast Score column from Double to Integer & filter empty filtered reviews\")\n",
    "filteredData = summaryAndTextFilteredData.withColumn(\"countSummaryFiltered\", countTokens(col(\"summaryFiltered\"))) \\\n",
    "                    .withColumn(\"countTextFiltered\", countTokens(col(\"textFiltered\"))) \\\n",
    "                    .withColumn(\"Score\", summaryAndTextFilteredData[\"Score\"].cast(IntegerType())) \\\n",
    "                    .filter('countSummaryFiltered > 0 and countTextFiltered > 0')\n",
    "\n",
    "# Release unused memory\n",
    "del summaryAndTextFilteredData\n",
    "\n",
    "print(\"Display results, after removing stop words\")\n",
    "filteredData.show(minNumOfTopRecords, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------\n",
      "Task 1\n",
      "------\n",
      "\n",
      "\n",
      "Task1.a\n",
      "-------\n",
      "Get avarage length of review text (and more statistical data):\n",
      "\n",
      "Avarage number of words in original review text, (before stop words removal & tokenization): 40.805728234118604 words.\n",
      "Avarage number of words in filtered review text, (after stop words removal & tokenization): 20.366836327546086 words.\n",
      "Maximum number of words in original review text, (before words removal & tokenization): 593 words.\n",
      "Minimum number of words in original review text, (before words removal & tokenization): 3 words.\n",
      "Maximum number of words in filtered review text, (after words removal & tokenization): 281 words.\n",
      "Minimum number of words in filtered review text, (after words removal & tokenization): 1 words.\n",
      "\n",
      "\n",
      "Task1.b\n",
      "-------\n",
      "We should use summary column, in order to predict score column\n",
      "\n",
      "\n",
      "Task1.c\n",
      "-------\n",
      "Check if there is missing data:\n",
      "In the original input data set, there are 46 reviews with missing summary\n",
      "The missing data has been filtered out. Therefore in the filtered data there are no missing fields\n",
      "\n",
      "\n",
      "Task1.d\n",
      "-------\n",
      "Check exceptions in reviews:\n",
      "In order to understand the exceptional lengths in the reviews text, we will display a histograms of reviews text length, before and after cleaning the data\n",
      "\n",
      "\n",
      "Histogram of reviews text length before cleaning the data\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "Analyze countTextWords column\n",
      "-----------------------------\n",
      "\n",
      "top 10 original review text lengths with maximum number of reviews:\n",
      "+---------------------------+-----+\n",
      "|original review text length|count|\n",
      "+---------------------------+-----+\n",
      "|                         20| 5952|\n",
      "|                         21| 5580|\n",
      "|                         22| 5492|\n",
      "|                         24| 5329|\n",
      "|                         23| 5312|\n",
      "|                         25| 5019|\n",
      "|                         26| 4656|\n",
      "|                         27| 4536|\n",
      "|                         28| 4184|\n",
      "|                         29| 3944|\n",
      "+---------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      " 10 original review text lengths with minimum number of reviews:\n",
      "+---------------------------+-----+\n",
      "|original review text length|count|\n",
      "+---------------------------+-----+\n",
      "|                        218|    1|\n",
      "|                        259|    1|\n",
      "|                        346|    1|\n",
      "|                        253|    1|\n",
      "|                        271|    1|\n",
      "|                        251|    1|\n",
      "|                        246|    1|\n",
      "|                        243|    1|\n",
      "|                        350|    1|\n",
      "|                        593|    1|\n",
      "+---------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Histogram of reviews text length after cleaning the data\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Analyze countTextFiltered column\n",
      "--------------------------------\n",
      "\n",
      "top 10 filtered review text lengths with maximum number of reviews:\n",
      "+---------------------------+-----+\n",
      "|filtered review text length|count|\n",
      "+---------------------------+-----+\n",
      "|                         13| 9643|\n",
      "|                         12| 9536|\n",
      "|                         14| 8921|\n",
      "|                         11| 8880|\n",
      "|                         15| 8136|\n",
      "|                         10| 7685|\n",
      "|                         16| 7418|\n",
      "|                         17| 6756|\n",
      "|                         18| 6132|\n",
      "|                          9| 5806|\n",
      "+---------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      " 10 filtered review text lengths with minimum number of reviews:\n",
      "+---------------------------+-----+\n",
      "|filtered review text length|count|\n",
      "+---------------------------+-----+\n",
      "|                        169|    1|\n",
      "|                        152|    1|\n",
      "|                        205|    1|\n",
      "|                        185|    1|\n",
      "|                        177|    1|\n",
      "|                        137|    1|\n",
      "|                        148|    1|\n",
      "|                        133|    1|\n",
      "|                        159|    1|\n",
      "|                        155|    1|\n",
      "+---------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In addition to histograms display, we will explore exceptional length, using the magic_percentile method.\n",
      "Scores grouped by percentiles review length:\n",
      "+-----+-------------------------------------------+\n",
      "|score|review text length magic percentiles values|\n",
      "+-----+-------------------------------------------+\n",
      "|5    |[34, 16, 10, 7, 5, 1, 1]                   |\n",
      "|4    |[37, 17, 10, 7, 5, 3, 3]                   |\n",
      "|3    |[40, 18, 10, 6, 5, 3, 3]                   |\n",
      "|2    |[40, 18, 10, 7, 4, 3, 3]                   |\n",
      "|1    |[39, 18, 10, 7, 5, 1, 1]                   |\n",
      "+-----+-------------------------------------------+\n",
      "\n",
      "Short review frequencies found.\n",
      "Short reviews occuur in the data set at a frequency of '0.0001'\n",
      "Short Review lengths to be filtered (ordered by index of the suitable score)\n",
      "[1, 3, 3, 3, 1]\n",
      "Filter out short reviews\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task 1\")\n",
    "\n",
    "displaySubTitle(\"Task1.a\")\n",
    "print(\"Get avarage length of review text (and more statistical data):\\n\")\n",
    "\n",
    "mean_original_review_len = filteredData.agg(F.mean('countTextWords'))\n",
    "mean_filtered_review_len = filteredData.agg(F.mean('countTextFiltered'))\n",
    "\n",
    "print(\"Avarage number of words in original review text, (before stop words removal & tokenization): \" + repr(mean_original_review_len.head()[0]) + \" words.\")\n",
    "print(\"Avarage number of words in filtered review text, (after stop words removal & tokenization): \" + repr(mean_filtered_review_len.head()[0]) + \" words.\")\n",
    "\n",
    "max_original_review_len = filteredData.agg(F.max(\"countTextWords\"))\n",
    "min_original_review_len = filteredData.agg(F.min(\"countTextWords\"))\n",
    "max_filtered_review_len = filteredData.agg(F.max(\"countTextFiltered\"))\n",
    "min_filtered_review_len = filteredData.agg(F.min(\"countTextFiltered\"))\n",
    "print(\"Maximum number of words in original review text, (before words removal & tokenization): \" + repr(max_original_review_len.head()[0]) + \" words.\")\n",
    "print(\"Minimum number of words in original review text, (before words removal & tokenization): \" + repr(min_original_review_len.head()[0]) + \" words.\")\n",
    "print(\"Maximum number of words in filtered review text, (after words removal & tokenization): \" + repr(max_filtered_review_len.head()[0]) + \" words.\")\n",
    "print(\"Minimum number of words in filtered review text, (after words removal & tokenization): \" + repr(min_filtered_review_len.head()[0]) + \" words.\")\n",
    "\n",
    "displaySubTitle(\"Task1.b\")\n",
    "print(\"We should use \" + textColumnTitle + \" column, in order to predict score column\")\n",
    "\n",
    "displaySubTitle(\"Task1.c\")\n",
    "print(\"Check if there is missing data:\")\n",
    "\n",
    "missing_text_count = reviews_df.filter((reviews_df[textColumn] == \"\") | reviews_df[textColumn].isNull() | F.isnan(reviews_df[textColumn])).count()\n",
    "\n",
    "# Release unused memory\n",
    "del reviews_df\n",
    "\n",
    "if missing_text_count == 0 :\n",
    "    print(\"In the original input data set there is no missing data.\")\n",
    "else:\n",
    "    print(\"In the original input data set, there are \" + repr(missing_text_count) + \" reviews with missing \" + textColumnTitle)\n",
    "    print(\"The missing data has been filtered out. Therefore in the filtered data there are no missing fields\")\n",
    "    \n",
    "displaySubTitle(\"Task1.d\")\n",
    "print(\"Check exceptions in reviews:\")\n",
    "\n",
    "print(\"In order to understand the exceptional lengths in the reviews text, we will display a histograms of reviews text length, before and after cleaning the data\")\n",
    "\n",
    "displaySubTitle(\"Histogram of reviews text length before cleaning the data\")\n",
    "analyzeColumn(filteredData, \"countTextWords\", \"original review text length\", \"review\", 1)\n",
    "displaySubTitle(\"Histogram of reviews text length after cleaning the data\")\n",
    "analyzeColumn(filteredData, \"countTextFiltered\", \"filtered review text length\", \"review\", 1)\n",
    "\n",
    "\n",
    "print(\"In addition to histograms display, we will explore exceptional length, using the magic_percentile method.\")\n",
    "\n",
    "print(\"Scores grouped by percentiles review length:\")\n",
    "grp_window = Window.partitionBy('score')\n",
    "magic_percentiles_values = '0.9, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001'\n",
    "magic_percentile_alias = \"review text length magic percentiles values\"\n",
    "magic_percentile = F.expr('percentile_approx(countTextFiltered, array(' + magic_percentiles_values + '))')\n",
    "magic_percentile_score_reviews_length_df = filteredData.groupBy('score').agg(magic_percentile.alias(magic_percentile_alias)).orderBy(\"score\", ascending=False)\n",
    "magic_percentile_score_reviews_length_df.show(truncate = False)\n",
    "\n",
    "magic_percentiles = [row[0] for row in magic_percentile_score_reviews_length_df.select(magic_percentile_alias).collect()]\n",
    "m = len(magic_percentiles)\n",
    "n = len(magic_percentiles[0])\n",
    "is_duplicate_column = False\n",
    "\n",
    "for j in range(n - 1):\n",
    "    counter = 0\n",
    "    for i in range(m):\n",
    "        if magic_percentiles[i][j] != magic_percentiles[i][j + 1]:\n",
    "            break\n",
    "    if i == m - 1:\n",
    "        is_duplicate_column = True\n",
    "        break\n",
    "\n",
    "short_review_frequency = magic_percentiles_values.split(\", \")[j]\n",
    "if is_duplicate_column:\n",
    "    print(\"Short review frequencies found.\")\n",
    "\n",
    "print(\"Short reviews occuur in the data set at a frequency of \" + repr(short_review_frequency))\n",
    "irrelevant_review_length_list = []\n",
    "for magic_percentile in magic_percentiles:\n",
    "    irrelevant_review_length_list.append(magic_percentile[j])\n",
    "    \n",
    "print(\"Short Review lengths to be filtered (ordered by index of the suitable score)\")\n",
    "print(irrelevant_review_length_list)\n",
    "\n",
    "print(\"Filter out short reviews\")\n",
    "cleanData = filteredData.rdd.filter(lambda line: line['countTextFiltered'] >  irrelevant_review_length_list[int(line['Score']) - 1]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "In this section, we try to find a corellation between negative words and score column\n",
      "-------------------------------------------------------------------------------------\n",
      "We will try to find correlation between negative words in the text column and the score column\n",
      "For this purpose, we will use the StopWordsRemover mechanism, in order to filter out negative words from the filtered text (filtered, because stop words have already been removed)\n",
      "Define negative words remover, with the list of negative words\n",
      "We use the StopWordsRemover mechanism to filter out negative words\n",
      "Define poswitive words remover, with the list of positive words\n",
      "We use the StopWordsRemover mechanism to filter out positive words\n",
      "Remove negative words\n",
      "Remove positive words\n",
      "Display results, after removing negative & positive words\n",
      "+---+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "|Id |Score|Text                                                                                                                                                                                                                                                                |textFiltered                                                                                                                                                                                |countTextfiltered|negative_filtered                                                                                                                                                    |count_negative_filtered|positive_filtered                                                                                                                                          |count_positive_filtered|count_negative|count_positive|\n",
      "+---+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "|1  |5    |i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than  most|[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]|23               |[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, processed, meat, better, labrador, appreciates, product, better]|20                     |[bought, several, canned, dog, products, found, product, looks, stew, processed, meat, smells, labrador, finicky, product]                                 |15                     |3             |8             |\n",
      "|2  |1    |product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo                                                                             |[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]                                 |18               |[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, vendor, intended, represent, product, jumbo]                 |17                     |[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]|18                     |1             |0             |\n",
      "|4  |2    |if you are looking for the secret ingredient in robitussin i believe i have found it  i got this in addition to the root beer extract i ordered which was good and made some cherry soda  the flavor is very medicinal                                              |[looking, secret, ingredient, robitussin, believe, found, got, addition, root, beer, extract, ordered, good, made, cherry, soda, flavor, medicinal]                                         |18               |[looking, secret, ingredient, robitussin, believe, found, got, addition, root, beer, extract, ordered, good, made, cherry, soda, flavor, medicinal]                  |18                     |[looking, secret, ingredient, robitussin, believe, found, got, root, beer, extract, ordered, made, cherry, soda, flavor, medicinal]                        |16                     |0             |2             |\n",
      "|9  |5    |right now im mostly just sprouting this so my cats can eat the grass they love it i rotate it around with wheatgrass and rye too                                                                                                                                    |[right, im, mostly, sprouting, cats, eat, grass, love, rotate, around, wheatgrass, rye]                                                                                                     |12               |[right, im, mostly, sprouting, cats, eat, grass, love, rotate, around, wheatgrass, rye]                                                                              |12                     |[right, im, mostly, sprouting, cats, eat, grass, rotate, around, wheatgrass, rye]                                                                          |11                     |0             |1             |\n",
      "|10 |5    |this is a very healthy dog food good for their digestion also good for small puppies my dog eats her required amount at every feeding                                                                                                                               |[healthy, dog, food, good, digestion, also, good, small, puppies, dog, eats, required, amount, every, feeding]                                                                              |15               |[healthy, dog, food, good, digestion, also, good, small, puppies, dog, eats, required, amount, every, feeding]                                                       |15                     |[dog, digestion, also, small, dog, eats, required, amount, every, feeding]                                                                                 |10                     |0             |5             |\n",
      "|14 |4    |good flavor these came securely packed they were fresh and delicious i love these twizzlers                                                                                                                                                                         |[good, flavor, came, securely, packed, fresh, delicious, love, twizzlers]                                                                                                                   |9                |[good, flavor, came, securely, packed, fresh, delicious, love, twizzlers]                                                                                            |9                      |[flavor, came, securely, packed, fresh, twizzlers]                                                                                                         |6                      |0             |3             |\n",
      "|15 |5    |the strawberry twizzlers are my guilty pleasure  yummy six pounds will be around for a while with my son and i                                                                                                                                                      |[strawberry, twizzlers, guilty, pleasure, yummy, six, pounds, around, son]                                                                                                                  |9                |[strawberry, twizzlers, pleasure, yummy, six, pounds, around, son]                                                                                                   |8                      |[strawberry, twizzlers, guilty, six, pounds, around, son]                                                                                                  |7                      |1             |2             |\n",
      "|17 |2    |i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them                                                                    |[love, eating, good, watching, tv, looking, movies, sweet, like, transfer, zip, lock, baggie, stay, fresh, take, time, eating]                                                              |18               |[love, eating, good, watching, tv, looking, movies, sweet, like, transfer, zip, lock, baggie, stay, fresh, take, time, eating]                                       |18                     |[eating, watching, tv, looking, movies, transfer, zip, lock, baggie, stay, fresh, take, eating]                                                            |13                     |0             |5             |\n",
      "|18 |5    |i am very satisfied with my twizzler purchase  i shared these with others and we have all enjoyed them  i will definitely be ordering more                                                                                                                          |[satisfied, twizzler, purchase, shared, others, enjoyed, definitely, ordering]                                                                                                              |8                |[satisfied, twizzler, purchase, shared, others, enjoyed, definitely, ordering]                                                                                       |8                      |[twizzler, purchase, shared, others, enjoyed, definitely, ordering]                                                                                        |7                      |0             |1             |\n",
      "|20 |5    |candy was delivered very fast and was purchased at a reasonable price  i was home bound and unable to get to a store so this was perfect for me                                                                                                                     |[candy, delivered, fast, purchased, reasonable, price, home, bound, unable, get, store, perfect]                                                                                            |12               |[candy, delivered, fast, purchased, reasonable, price, home, bound, get, store, perfect]                                                                             |11                     |[candy, delivered, fast, purchased, reasonable, price, home, bound, unable, get, store]                                                                    |11                     |1             |1             |\n",
      "+---+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Sample 10000 records, in order to check for a possible correlation between negative words and score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe plot shows that there is no correlation between negative words and score.\\nTherefore we should choose a different model for predicting score, based on the text.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayTitle(\"In this section, we try to find a corellation between negative words and score column\")\n",
    "print(\"We will try to find correlation between negative words in the text column and the score column\")\n",
    "print(\"For this purpose, we will use the StopWordsRemover mechanism, in order to filter out negative words from the filtered text (filtered, because stop words have already been removed)\")\n",
    "\n",
    "print(\"Define negative words remover, with the list of negative words\")\n",
    "print(\"We use the StopWordsRemover mechanism to filter out negative words\")\n",
    "negative_remover = StopWordsRemover(inputCol='textFiltered', outputCol=\"negative_filtered\", stopWords=negative_words)\n",
    "\n",
    "print(\"Define poswitive words remover, with the list of positive words\")\n",
    "print(\"We use the StopWordsRemover mechanism to filter out positive words\")\n",
    "positive_remover = StopWordsRemover(inputCol='textFiltered', outputCol=\"positive_filtered\", stopWords=positive_words)\n",
    "\n",
    "print(\"Remove negative words\")\n",
    "filteredDataWithoutNegativeWords = negative_remover.transform(filteredData).withColumn(\"count_negative_filtered\", countTokens(col(\"negative_filtered\")))\n",
    "\n",
    "print(\"Remove positive words\")\n",
    "filteredDataWithoutPositiveWords = positive_remover.transform(filteredDataWithoutNegativeWords).withColumn(\"count_positive_filtered\", countTokens(col(\"positive_filtered\")))\n",
    "\n",
    "filteredDataWithoutNegativeAndPositiveWords = filteredDataWithoutPositiveWords \\\n",
    "            .select(\"Id\", \"Score\", 'Text', 'textFiltered', 'countTextfiltered', \"negative_filtered\", \"count_negative_filtered\", \"positive_filtered\", \"count_positive_filtered\") \\\n",
    "            .withColumn(\"count_negative\", col('countTextFiltered') - col(\"count_negative_filtered\")) \\\n",
    "            .withColumn(\"count_positive\", col('countTextFiltered') - col(\"count_positive_filtered\"))\n",
    "\n",
    "# Release unused memory\n",
    "del filteredDataWithoutNegativeWords\n",
    "del filteredDataWithoutPositiveWords\n",
    "\n",
    "print(\"Display results, after removing negative & positive words\")\n",
    "filteredDataWithoutNegativeAndPositiveWords.show(numOfTopRecords, truncate = False)\n",
    "\n",
    "print(\"Sample \" + repr(numOfSamplingDefaultRecords) + \" records, in order to check for a possible correlation between negative words and score\")\n",
    "num_of_records = filteredDataWithoutNegativeAndPositiveWords.count()\n",
    "percentage = 1.0 if num_of_records < numOfSamplingDefaultRecords else numOfSamplingDefaultRecords / num_of_records\n",
    "df_pandas = filteredDataWithoutNegativeAndPositiveWords.sample(False, percentage, filterWordsSeed).toPandas()\n",
    "plt.scatter(df_pandas['Score'], df_pandas['count_negative'],  lineWidth = 2.0)\n",
    "\n",
    "# Release unused memory\n",
    "del df_pandas\n",
    "\n",
    "'''\n",
    "The plot shows that there is no correlation between negative words and score.\n",
    "Therefore we should choose a different model for predicting score, based on the text.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------\n",
      "Task1.e\n",
      "-------\n",
      "\n",
      "\n",
      "Examples of cynical and bad reviews:\n",
      "------------------------------------\n",
      "Fetch bad reviews...\n",
      "Fetch cynical reviews...\n",
      "13333 examples of bad reviews:\n",
      "+---+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "|Id |Score|Text                                                                                                                                                                                   |textFiltered                                                                                                                                               |countTextfiltered|negative_filtered                                                                                                                                   |count_negative_filtered|positive_filtered                                                                                                                                          |count_positive_filtered|count_negative|count_positive|\n",
      "+---+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "|2  |1    |product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo|[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]|18               |[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, vendor, intended, represent, product, jumbo]|17                     |[product, arrived, labeled, jumbo, salted, peanutsthe, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]|18                     |1             |0             |\n",
      "|63 |1    |arrived in 6 days and were so stale i could not eat any of the 6 bags                                                                                                                  |[arrived, 6, days, stale, eat, 6, bags]                                                                                                                    |7                |[arrived, 6, days, eat, 6, bags]                                                                                                                    |6                      |[arrived, 6, days, stale, eat, 6, bags]                                                                                                                    |7                      |1             |0             |\n",
      "+---+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Out of the bad reviews, there are 52 examples of reviews that are probably cynical:\n",
      "+----+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "|Id  |Score|Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |textFiltered                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |countTextfiltered|negative_filtered                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |count_negative_filtered|positive_filtered                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |count_positive_filtered|count_negative|count_positive|\n",
      "+----+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "|2576|1    |im a little shocked that this socalled health food product is made from chinese grown ingredients  id be curious to see what the carbon footprint of each bite is  also keep in mind that chinese ingredients and products have been found to have all kinds of contaminants such as lead in toys and melamine in milk and other exported food products all the ingredients in this snack are widely available in the united states  why not support products and companies who source locally and consider our own economy before we sell out for a slightly cheaper price  your purchasing choice does make a difference  lets stop expecting corporations and governments to take care of our safety and economy  they never will  we can change the way these companies do business for the benefit of our long term health and economical wellbeing make purchase decisions wisely                                                                    |[im, little, shocked, socalled, health, food, product, made, chinese, grown, ingredients, id, curious, see, carbon, footprint, bite, also, keep, mind, chinese, ingredients, products, found, kinds, contaminants, lead, toys, melamine, milk, exported, food, products, ingredients, snack, widely, available, united, states, support, products, companies, source, locally, consider, economy, sell, slightly, cheaper, price, purchasing, choice, make, difference, lets, stop, expecting, corporations, governments, take, care, safety, economy, never, change, way, companies, business, benefit, long, term, health, economical, wellbeing, make, purchase, decisions, wisely]                                                        |78               |[im, little, socalled, health, food, product, made, chinese, grown, ingredients, id, curious, see, carbon, footprint, bite, also, keep, mind, chinese, ingredients, products, found, kinds, contaminants, lead, toys, melamine, milk, exported, food, products, ingredients, snack, widely, available, united, states, support, products, companies, source, locally, consider, economy, sell, slightly, cheaper, price, purchasing, choice, make, difference, lets, stop, expecting, corporations, governments, take, care, safety, economy, never, change, way, companies, business, benefit, long, term, health, economical, wellbeing, make, purchase, decisions, wisely]                              |77                     |[im, little, shocked, socalled, product, made, chinese, grown, ingredients, id, see, carbon, footprint, bite, also, keep, mind, chinese, ingredients, products, found, kinds, contaminants, lead, toys, melamine, milk, exported, products, ingredients, snack, widely, available, united, states, products, companies, source, locally, consider, economy, sell, slightly, cheaper, price, purchasing, make, difference, lets, stop, expecting, corporations, governments, take, economy, never, way, companies, business, long, term, economical, make, purchase, decisions, wisely]                                             |66                     |1             |12            |\n",
      "|2595|1    |i used to buy these as healthy snacks at my office cafeteria and consider it better than a bag of potato chips  these taste very crunchy and tastygiven the kind of unethical food stories we read about china  we need to see some kind of assurance and facts on the processes that the manufacturer is following to make these  you just cannot import food stuff and sell in the us as gourmet snack food  there needs to be data backing thisfew example of chinese food yuk 1 melaminekind of platic in baby food and milk so wide spread that 80 of milk in china contained this plastic in 20082 honey contaminated with ciprofloxacin antibiotic  because of which it was banned in the us3 soy sauce made from human hair not joking google it if you want4 spurious drugs exported to african countriesneed some good facts and quality controls from the manufacturers that the chinese producers are complying with some good quality controls|[used, buy, healthy, snacks, office, cafeteria, consider, better, bag, potato, chips, taste, crunchy, tastygiven, kind, unethical, food, stories, read, china, need, see, kind, assurance, facts, processes, manufacturer, following, make, import, food, stuff, sell, us, gourmet, snack, food, needs, data, backing, thisfew, example, chinese, food, yuk, 1, melaminekind, platic, baby, food, milk, wide, spread, 80, milk, china, contained, plastic, 20082, honey, contaminated, ciprofloxacin, antibiotic, banned, us3, soy, sauce, made, human, hair, joking, google, want4, spurious, drugs, exported, african, countriesneed, good, facts, quality, controls, manufacturers, chinese, producers, complying, good, quality, controls]|89               |[used, buy, healthy, snacks, office, cafeteria, consider, better, bag, potato, chips, taste, crunchy, tastygiven, kind, food, stories, read, china, need, see, kind, assurance, facts, processes, manufacturer, following, make, import, food, stuff, sell, us, gourmet, snack, food, needs, data, backing, thisfew, example, chinese, food, yuk, 1, melaminekind, platic, baby, food, milk, wide, spread, 80, milk, china, contained, plastic, 20082, honey, ciprofloxacin, antibiotic, banned, us3, soy, sauce, made, human, hair, joking, google, want4, drugs, exported, african, countriesneed, good, facts, quality, controls, manufacturers, chinese, producers, complying, good, quality, controls]|86                     |[used, buy, snacks, office, cafeteria, consider, bag, potato, chips, taste, crunchy, tastygiven, unethical, stories, read, china, need, see, facts, processes, manufacturer, following, make, import, stuff, sell, us, gourmet, snack, needs, data, backing, thisfew, example, chinese, yuk, 1, melaminekind, platic, baby, milk, wide, spread, 80, milk, china, contained, plastic, 20082, honey, contaminated, ciprofloxacin, antibiotic, banned, us3, soy, sauce, made, hair, joking, google, want4, spurious, drugs, exported, african, countriesneed, facts, controls, manufacturers, chinese, producers, complying, controls]|74                     |3             |15            |\n",
      "+----+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------+--------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "Sample bad reviews\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10 random bad reviews:\n",
      "----------------------\n",
      "9323: i tried a double boxes of this when the donut shop  coffee i usually order was unavailable  while the coffee is pretty good the cups suck  a full 13 of the cups brewed are undrinkable  they are slow to brewcoffee maker has to work very hard and even then the cup retains an inordinate amount of water  checking some of the cups that left grounds in the brew showed that the filter was not properly installed  they could sell these at half the price listed and you still would pay too much due to all the wasted coffee  i believe we all have experienced a defective cup here or there but these are way beyond acceptable\n",
      "208774: this product is poorly packed and half of the peanuts spilled out in the box and are no longer ebible i would recommend buying a product that is sealed in a better package\n",
      "238294: my dogs nearly died from eating chicken jerky treats from china kidney damage is permanent please think twice about using this treat\n",
      "242122: our one year old seal point siamese smelled this cat food  turned up her nose and walked away  i left in down for one day  she would not even touch itdonated this cat food to local rescure shelter for animals\n",
      "270417: received on 92210 only to find all 12 bags with sell date of august 22 2010  will get refund but bewareeven cartons have stamped goods must be rotated which i know means put out the oldest firstwell they rotated it to me  i wonder if thats anything like getting the shaft\n",
      "304541: the produt description is untrue  you dont get 850 you only get 200 it is not worth it trust me  i called the company in new york and they were not taking any responsibility for this problem  they were putting all the blame on amazon\n",
      "307390: sounds yummy  taste gross now i have two boxes of this stuff and no one wants it\n",
      "317443: this is the worst coffee we have ever bought from youwill never buy againit is so week taste like hot water i wasted my money on iti am not happy at all\n",
      "330156: i did not use this product after researching it and finding it could cause a false positive on a drug test  i could not find what type of test they are using but some of the jobs i currently have applications in for use hair tests and did not want to take the chance\n",
      "363837: i just bought a box of protein plus expecting it to be the protein plus i have eaten religiously over the past few years instead what i tasted was basically frosted flakes so i read the panel and saw that they had added 5g of sugar and reduced fiber seriously will be buying kashi or hilo from now on\n",
      "\n",
      "Sample cynical reviews\n",
      "\n",
      "\n",
      "6 random cynical reviews:\n",
      "-------------------------\n",
      "90147: i try to make sure that the products i consume are not only good for me but pleasantly flavored  i did not find vita coco to be the latter  the water was slightly sour and it was a real chore for me to finish a 17 ounce container  i had to brush my teeth after drinking it because the aftertaste was strongi love almost all things coconut but vita cocos beverage is not one of my favorite coconut based products  i know there are many that applaud the health benefits of this water and i know those benefits are great but this stuff has a terrible taste and i dont care how spectacular those benefits arethis product is produced in brazil\n",
      "309193: i like the convenience and quality of the kcups and thought the hot chocolate would be as good as the coffee and tea  the problem is the chocolate is a fine powder so it remains in the container instead of dissolving and flowing into the mug  it is better to run a mug of hot water from your keurig and then stir in your favorite packet of hot chocolate mix\n",
      "347336: whether you like this candy or not depends a lot on why you are buying itif you are older like me and looking for the red licorice that was once sold in department store candy counters and candy stores by the bunch in the sixties and seventies then you will be disappointed this is not even remotely similar to that candyuntil eight years ago our mall candy store sold the original red licorice laces but they replaced it with the kind that tastes like twizzlers in the form of a string i have been looking to no avail for the original variety ever since this order was my last hope and it seems the kind many of us grew up with simply isnt being made anymorepersonally i did not really care for the taste but that means nothing since i was looking for the kind they use to sell and this wasnt itif anyone does know who sells the original type i wish they would tell me\n",
      "373811: i was really excited when i received this as a gift my husband and i both have food allergies so i was planning on making our own baby food and the beabe babaycook seemed perfectat first it was great i loved being able to steam and then puree in one machine and i didnt mind the small portions because i am not a huge fan of leftovers so the fact that we would get only 4 servings a time was no big dealwe have used the machine 5 times 5 and we followed the care instructions to the letterimagine my surprise when we discovered small metal shavings in the food the only things we had cooked in the machine were sweat potatoes and peas nothing that should cause the blade to chip the only thing used to get the food out was a rubber spatula we discovered metal in the food when our microwave was arching while heating up a serving of sweet potatoes 24 sec power level 5do not buy seriouslythis machine is a hazard\n",
      "414301: i went back and forth on getting my girls some of the beef flavored newmans because 2 of the 3 cant eat chicken  i am always looking for a good quality food to add to their rotation  there was a pretty good sale on the beef flavored a few days ago so i bought it  i opened a can to give them for their dinner and i absolutely could not give that to my girls  it had an awful grey color to it and was the consistency of wall paper paste  my cats like to chew their food not lick it up so i knew they would have an awful time with this one  newmans has changed  i have tried most of the flavors over the years and i have noticed that the cans are underweight and seem to have almost as much rice as pate in them  will not be buying again but thank heaven for amazon that always makes it right without any hassles\n",
      "450934: i really like the taste of these bars and was very excited about the product  to find a healthy snack that tastes good is a rare find for me  then i read the lable and was a bit dissapointed  planters uses high fructos corn syrup in it and additional sugars  i dont understand why the honey wouldnt be enough to make it sweet  high fructos corn syrup is something that i need to avoid as it is very bad for my heart health  in fact i believe it is the worst kind of sugar there is although i originally gave this one star by accident and amazon wont let me rase that to a 3 star i do feel dissapointed in the health qualities of the product and probably wont be buying another batch any time soon\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task1.e\")\n",
    "displaySubTitle(\"Examples of cynical and bad reviews:\")\n",
    "'''\n",
    "\n",
    "Negative reviews identification strategy:\n",
    "-----------------------------------------\n",
    "It's easy - we just filter in all of the reviews with the lowest score (1).\n",
    "These reviews must be negative, because of their poor score.\n",
    "\n",
    "Cynical text identification strategy:\n",
    "-------------------------------------\n",
    "Usually, cynical review wiil have a low score, and a small amount of negative words.\n",
    "The positive words will criticise the product, and present it in a negative way.\n",
    "Therefore, out of the reviews with bad scores,\n",
    "we filter in reviews with many positive words,\n",
    "but just a few negative words (at most).\n",
    "Hopefully, this approach will discover the cynical reviews.\n",
    "\n",
    "'''\n",
    "\n",
    "def df_sample_to_list(df, df_count, num_of_sampling_records, column1, column1Alias, column2, column2Alias):\n",
    "    percentageRecords = 1.0 if df_count < num_of_sampling_records else num_of_sampling_records / df_count\n",
    "    sample_list = [{column1Alias: x[column1], column2Alias: x[column2]} \\\n",
    "                    for x in df.sample(False, percentageRecords, sampleRecordsSeed).limit(num_of_sampling_records).collect()]\n",
    "    return sample_list\n",
    "\n",
    "def print_sample_list(sample_list, title, column1, column2):\n",
    "    displaySubTitle(repr(len(sample_list)) + \" \" + title + \":\")\n",
    "    for row in sample_list:\n",
    "        print(\"{}: {}\".format(row[column1], row[column2]))\n",
    "\n",
    "print(\"Fetch bad reviews...\")\n",
    "badReviewsDF = filteredDataWithoutNegativeAndPositiveWords.rdd.filter(lambda line: line['Score'] ==  1).toDF()\n",
    "numBadReviewRecords = badReviewsDF.count()\n",
    "\n",
    "# Release unused memory\n",
    "del filteredDataWithoutNegativeAndPositiveWords\n",
    "\n",
    "print(\"Fetch cynical reviews...\")\n",
    "cynicalReviewsDF = badReviewsDF.rdd.filter(lambda line: line['count_negative'] <= maximumNumOfNegativeWords and line['count_positive'] > minimalNumOfPositiveWords).toDF()\n",
    "numCynicalReviewRecords = cynicalReviewsDF.count()\n",
    "\n",
    "print(repr(numBadReviewRecords) + \" examples of bad reviews:\")\n",
    "badReviewsDF.show(minNumOfTopRecords, truncate = False)\n",
    "\n",
    "print(\"Out of the bad reviews, there are \" + repr(numCynicalReviewRecords) + \" examples of reviews that are probably cynical:\")\n",
    "cynicalReviewsDF.show(minNumOfTopRecords, truncate = False)\n",
    "\n",
    "print(\"\\nSample bad reviews\")\n",
    "bad_reviews_list =  df_sample_to_list(badReviewsDF, numBadReviewRecords, numOfSamplingBadRecords, 'Id', 'id', 'Text', 'text')\n",
    "print_sample_list(bad_reviews_list, 'random bad reviews', 'id', 'text')\n",
    "\n",
    "print(\"\\nSample cynical reviews\")\n",
    "cynical_reviews_list =  df_sample_to_list(cynicalReviewsDF, numCynicalReviewRecords, numOfSamplingCynicalRecords, 'Id', 'id', 'Text', 'text')\n",
    "print_sample_list(cynical_reviews_list, 'random cynical reviews', 'id', 'text')\n",
    "\n",
    "# Release unused memory\n",
    "del badReviewsDF\n",
    "del cynicalReviewsDF\n",
    "del bad_reviews_list\n",
    "del cynical_reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------\n",
      "Task2 (a+b)\n",
      "-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nType of model:\\n-------------\\nThere is no need to predict a binary answer (positive or negative review), since the score column is provided.\\nTherefore, the score will be predicted based on the Text.\\nIt means that this is a classification problem with 5 classes.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayTitle(\"Task2 (a+b)\")\n",
    "'''\n",
    "Type of model:\n",
    "-------------\n",
    "There is no need to predict a binary answer (positive or negative review), since the score column is provided.\n",
    "Therefore, the score will be predicted based on the Text.\n",
    "It means that this is a classification problem with 5 classes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Task3\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n3.a Evaluation method:\\nConfusion matrix - https://towardsdatascience.com/model-evaluation-techniques-for-classification-models-eac30092c38b\\n\\nThe correct classification will be determined by the Score column.\\n\\n-------------------\\n|True    |False   |\\n|Positive|Positive|\\n-------------------\\n|False   |True    |\\n|Negative|Negative|\\n-------------------\\n\\n\\nAccuarcy = (TP + TN) / (TP + TN + FP + FN)\\nPrecission = TP / (TP + FP)\\nRecall = Sensitivity = TP / (TP + FN)\\n\\nAccuarcy - how often is the model correct?\\nPrecission - When the model predicts positive results, how often is it correct?\\nRecall - When it is actually the positive result, how often does it predict correctly?\\n\\n\\nIn our case it's not a binary classification problem, but a multi-class classification problem.\\nTherefore the conusion matrix dimensions are: 5X5\\nWhere the main diaogonal is the TP values.\\n\\nAll of the column (excluding TP values) are FN\\nAll of the rows (excluding TP values) are FP\\n\\nWe have 5 classes that represents a given score: 1,2,3,4,5\\n\\nThe total number of test examples of any class,\\nwould be the sum of the corresponding row (i.e the TP+FN for that class)\\n\\nThe total number of FN's for a class,\\nis the sum of values in the corresponding row (excluding the TP)\\n\\nThe total number of FP's for a class,\\nis the sum of values in the corresponding column (excluding the TP)\\n\\nThe total number of TN's for a class,\\nis the sum of all columns and rows, exluding that class' column and row\\n\\nThe Recall, commonly called sensitivity,\\ncorespponds to the true-positive-rate of the considered class.\\n\\n\\n\\n\\n                        PREDICTED\\n         |--------------------------------------------\\nACTUAL   |   1        2        3        4        5\\n       1 | TP[1]     E[1,2]   E[1,3]   E[1,4]   E[1,5]\\n       2 | E[2,1]    TP[2]    E[2,3]   E[2,4]   E[2,5]\\n       3 | E[3,1]    E[3,2]   TP[3]    E[3,4]   E[3,5]\\n       4 | E[4,1]    E[4,2]   E[4,3]   TP[4]    E[4,5]\\n       5 | E[5,1]    E[5,2]   E[5,3]   E[5,4]   TP[5]\\n\\n\\nPrecision 1 = TP[1] / (TP[1] + E[2,1] + E[3,1] + E[4,1] + E[5,1])\\nPrecision 2 = TP[2] / (TP[2] + E[1,2] + E[3,2] + E[4,2] + E[5,2])\\nPrecision 3 = TP[3] / (TP[3] + E[1,3] + E[2,3] + E[4,3] + E[5,3])\\nPrecision 4 = TP[4] / (TP[4] + E[1,4] + E[2,4] + E[3,4] + E[5,4])\\nPrecision 5 = TP[5] / (TP[5] + E[1,5] + E[2,5] + E[3,5] + E[4,5])\\n\\n\\nRecall 1 = Sensitivity 1 = TP[1] / (TP[1] + E[1,2] + E[1,3] + E[1,4] + E[1,5])\\nRecall 2 = Sensitivity 2 = TP[2] / (TP[2] + E[2,1] + E[2,3] + E[2,4] + E[2,5])\\nRecall 3 = Sensitivity 3 = TP[3] / (TP[3] + E[3,1] + E[3,2] + E[3,3] + E[3,4])\\nRecall 4 = Sensitivity 4 = TP[4] / (TP[4] + E[4,1] + E[4,2] + E[4,3] + E[4,5])\\nRecall 5 = Sensitivity 5 = TP[5] / (TP[5] + E[5,1] + E[5,2] + E[5,3] + E[5,4])\\n\\n\\n3.b Features to be used:\\nText column\\n\\n3.c Model description:\\nA classifier that predict score (5 possible classes), based on text column (vectorized)\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displaySubTitle(\"Task3\")\n",
    "\n",
    "'''\n",
    "3.a Evaluation method:\n",
    "Confusion matrix - https://towardsdatascience.com/model-evaluation-techniques-for-classification-models-eac30092c38b\n",
    "\n",
    "The correct classification will be determined by the Score column.\n",
    "\n",
    "-------------------\n",
    "|True    |False   |\n",
    "|Positive|Positive|\n",
    "-------------------\n",
    "|False   |True    |\n",
    "|Negative|Negative|\n",
    "-------------------\n",
    "\n",
    "\n",
    "Accuarcy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precission = TP / (TP + FP)\n",
    "Recall = Sensitivity = TP / (TP + FN)\n",
    "\n",
    "Accuarcy - how often is the model correct?\n",
    "Precission - When the model predicts positive results, how often is it correct?\n",
    "Recall - When it is actually the positive result, how often does it predict correctly?\n",
    "\n",
    "\n",
    "In our case it's not a binary classification problem, but a multi-class classification problem.\n",
    "Therefore the conusion matrix dimensions are: 5X5\n",
    "Where the main diaogonal is the TP values.\n",
    "\n",
    "All of the column (excluding TP values) are FN\n",
    "All of the rows (excluding TP values) are FP\n",
    "\n",
    "We have 5 classes that represents a given score: 1,2,3,4,5\n",
    "\n",
    "The total number of test examples of any class,\n",
    "would be the sum of the corresponding row (i.e the TP+FN for that class)\n",
    "\n",
    "The total number of FN's for a class,\n",
    "is the sum of values in the corresponding row (excluding the TP)\n",
    "\n",
    "The total number of FP's for a class,\n",
    "is the sum of values in the corresponding column (excluding the TP)\n",
    "\n",
    "The total number of TN's for a class,\n",
    "is the sum of all columns and rows, exluding that class' column and row\n",
    "\n",
    "The Recall, commonly called sensitivity,\n",
    "corespponds to the true-positive-rate of the considered class.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        PREDICTED\n",
    "         |--------------------------------------------\n",
    "ACTUAL   |   1        2        3        4        5\n",
    "       1 | TP[1]     E[1,2]   E[1,3]   E[1,4]   E[1,5]\n",
    "       2 | E[2,1]    TP[2]    E[2,3]   E[2,4]   E[2,5]\n",
    "       3 | E[3,1]    E[3,2]   TP[3]    E[3,4]   E[3,5]\n",
    "       4 | E[4,1]    E[4,2]   E[4,3]   TP[4]    E[4,5]\n",
    "       5 | E[5,1]    E[5,2]   E[5,3]   E[5,4]   TP[5]\n",
    "\n",
    "\n",
    "Precision 1 = TP[1] / (TP[1] + E[2,1] + E[3,1] + E[4,1] + E[5,1])\n",
    "Precision 2 = TP[2] / (TP[2] + E[1,2] + E[3,2] + E[4,2] + E[5,2])\n",
    "Precision 3 = TP[3] / (TP[3] + E[1,3] + E[2,3] + E[4,3] + E[5,3])\n",
    "Precision 4 = TP[4] / (TP[4] + E[1,4] + E[2,4] + E[3,4] + E[5,4])\n",
    "Precision 5 = TP[5] / (TP[5] + E[1,5] + E[2,5] + E[3,5] + E[4,5])\n",
    "\n",
    "\n",
    "Recall 1 = Sensitivity 1 = TP[1] / (TP[1] + E[1,2] + E[1,3] + E[1,4] + E[1,5])\n",
    "Recall 2 = Sensitivity 2 = TP[2] / (TP[2] + E[2,1] + E[2,3] + E[2,4] + E[2,5])\n",
    "Recall 3 = Sensitivity 3 = TP[3] / (TP[3] + E[3,1] + E[3,2] + E[3,3] + E[3,4])\n",
    "Recall 4 = Sensitivity 4 = TP[4] / (TP[4] + E[4,1] + E[4,2] + E[4,3] + E[4,5])\n",
    "Recall 5 = Sensitivity 5 = TP[5] / (TP[5] + E[5,1] + E[5,2] + E[5,3] + E[5,4])\n",
    "\n",
    "\n",
    "3.b Features to be used:\n",
    "Text column\n",
    "\n",
    "3.c Model description:\n",
    "A classifier that predict score (5 possible classes), based on text column (vectorized)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task4\n",
      "-----\n",
      "\n",
      "\n",
      "Vectorization of reviews\n",
      "------------------------\n",
      "Building binary hashing TF\n",
      "Binary vectors of text as features:\n",
      "+---+-----+--------------------------+-------------------------------------------------------+\n",
      "|id |Score|summaryFiltered           |rawFeatures                                            |\n",
      "+---+-----+--------------------------+-------------------------------------------------------+\n",
      "|1  |5    |[good, quality, dog, food]|(262144,[75919,113432,121133,250865],[1.0,1.0,1.0,1.0])|\n",
      "|2  |1    |[advertised]              |(262144,[232199],[1.0])                                |\n",
      "+---+-----+--------------------------+-------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "\n",
      "Building hashing TF (non-binary)\n",
      "Vectors of text as features (non-binary):\n",
      "+---+-----+------------------------------+-------------------------------------------------------+\n",
      "|id |Score|summaryFiltered               |rawFeatures                                            |\n",
      "+---+-----+------------------------------+-------------------------------------------------------+\n",
      "|1  |5    |[good, quality, dog, food]    |(262144,[75919,113432,121133,250865],[1.0,1.0,1.0,1.0])|\n",
      "|2  |1    |[advertised]                  |(262144,[232199],[1.0])                                |\n",
      "|4  |2    |[cough, medicine]             |(262144,[86037,194543],[1.0,1.0])                      |\n",
      "|9  |5    |[yay, barley]                 |(262144,[74225,210101],[1.0,1.0])                      |\n",
      "|10 |5    |[healthy, dog, food]          |(262144,[75919,121133,163287],[1.0,1.0,1.0])           |\n",
      "|14 |4    |[fresh, greasy]               |(262144,[74475,199014],[1.0,1.0])                      |\n",
      "|15 |5    |[strawberry, twizzlers, yummy]|(262144,[78,212094,213560],[1.0,1.0,1.0])              |\n",
      "|17 |2    |[poor, taste]                 |(262144,[85735,101702],[1.0,1.0])                      |\n",
      "|18 |5    |[love]                        |(262144,[186480],[1.0])                                |\n",
      "|20 |5    |[home, delivered, twizlers]   |(262144,[17893,189658,232222],[1.0,1.0,1.0])           |\n",
      "|23 |5    |[delicious, product]          |(262144,[81008,146009],[1.0,1.0])                      |\n",
      "|24 |5    |[twizzlers]                   |(262144,[212094],[1.0])                                |\n",
      "|28 |4    |[great, bargain, price]       |(262144,[35607,87603,138356],[1.0,1.0,1.0])            |\n",
      "|43 |5    |[foodgreat]                   |(262144,[192996],[1.0])                                |\n",
      "|45 |5    |[great, taste, convenience]   |(262144,[101702,138356,248591],[1.0,1.0,1.0])          |\n",
      "|47 |5    |[good]                        |(262144,[113432],[1.0])                                |\n",
      "|50 |3    |[stuff]                       |(262144,[33209],[1.0])                                 |\n",
      "|54 |3    |[ass, kickin]                 |(262144,[235905,254786],[1.0,1.0])                     |\n",
      "|57 |5    |[awesome, deal]               |(262144,[82495,165865],[1.0,1.0])                      |\n",
      "|63 |1    |[stale, product]              |(262144,[81008,144940],[1.0,1.0])                      |\n",
      "+---+-----+------------------------------+-------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "================================================================================================================\n",
      "\n",
      "Building TF-IDF\n",
      "TF-IDF features:\n",
      "+---+-----+--------------------------+-------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+\n",
      "|id |Score|summaryFiltered           |rawFeatures                                            |features                                                                                                        |\n",
      "+---+-----+--------------------------+-------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+\n",
      "|1  |5    |[good, quality, dog, food]|(262144,[75919,113432,121133,250865],[1.0,1.0,1.0,1.0])|(262144,[75919,113432,121133,250865],[3.707254672918943,2.557945807025675,3.9549456970835823,4.978075889385797])|\n",
      "|2  |1    |[advertised]              |(262144,[232199],[1.0])                                |(262144,[232199],[7.1084520545810985])                                                                          |\n",
      "+---+-----+--------------------------+-------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task4\")\n",
    "displaySubTitle(\"Vectorization of reviews\")\n",
    "\n",
    "cleanFilteredData = cleanData.select('id', 'Score', 'summaryFiltered')\n",
    "\n",
    "# Release unused memory\n",
    "del filteredData\n",
    "del cleanData\n",
    "\n",
    "print(\"Building binary hashing TF\")\n",
    "binaryHashingTF = HashingTF().setInputCol(\"summaryFiltered\").setOutputCol(\"rawFeatures\").setBinary(True)\n",
    "binary_tf = binaryHashingTF.transform(cleanFilteredData)\n",
    "print(\"Binary vectors of text as features:\")\n",
    "binary_tf.show(minNumOfTopRecords, truncate = False)\n",
    "\n",
    "print(\"\\n================================================================================================================\\n\")\n",
    "\n",
    "print(\"Building hashing TF (non-binary)\")\n",
    "hashingTF = HashingTF().setInputCol(\"summaryFiltered\").setOutputCol(\"rawFeatures\")\n",
    "tf = hashingTF.transform(cleanFilteredData)\n",
    "print(\"Vectors of text as features (non-binary):\")\n",
    "tf.show(maxNumOfTopRecords, truncate = False)\n",
    "\n",
    "# Release unused memory\n",
    "del cleanFilteredData\n",
    "\n",
    "print(\"\\n================================================================================================================\\n\")\n",
    "\n",
    "print(\"Building TF-IDF\")\n",
    "idf = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(minDocFreq)\n",
    "idfModel = idf.fit(tf)\n",
    "tfidf = idfModel.transform(tf)\n",
    "print(\"TF-IDF features:\")\n",
    "tfidf.show(minNumOfTopRecords, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task5\n",
      "-----\n",
      "\n",
      "\n",
      "Splitting the data to train & test set with (0.7,0.3) ratio\n",
      "-----------------------------------------------------------\n",
      "Selecting score & feature columns\n",
      "Splitting binart tf vectors to train & test sets\n",
      "Splitting tf-idf vectors to train & test sets\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task5\")\n",
    "displaySubTitle(\"Splitting the data to train & test set with (0.7,0.3) ratio\")\n",
    "\n",
    "print(\"Selecting score & feature columns\")\n",
    "binary_tf_labeled = binary_tf.select('Score', 'rawFeatures') \\\n",
    "            .withColumn(\"Score\", tf[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumnRenamed(\"Score\", \"label\") \\\n",
    "            .withColumnRenamed(\"rawFeatures\", \"features\")\n",
    "tf_labeled = tf.select('Score', 'rawFeatures') \\\n",
    "            .withColumn(\"Score\", tf[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumnRenamed(\"Score\", \"label\") \\\n",
    "            .withColumnRenamed(\"rawFeatures\", \"features\")\n",
    "tfidf_labeled = tfidf.select('Score', 'features') \\\n",
    "            .withColumn(\"Score\", tfidf[\"Score\"].cast(IntegerType())) \\\n",
    "            .withColumnRenamed(\"Score\", \"label\")\n",
    "\n",
    "print(\"Splitting binart tf vectors to train & test sets\")\n",
    "train_set_binary_tf, test_set_binary_tf = binary_tf_labeled.randomSplit(randomSplit, seed=dataSplitSeed)\n",
    "\n",
    "# print(\"Splitting tf vectors to train & test sets\")\n",
    "# train_set_tf, test_set_tf = tf_labeled.randomSplit(randomSplit, seed=dataSplitSeed)\n",
    "\n",
    "print(\"Splitting tf-idf vectors to train & test sets\")\n",
    "train_set_tfidf, test_set_tfidf = tfidf_labeled.randomSplit(randomSplit, seed=dataSplitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyData(classifier, train_set, test_set, paramGrid):\n",
    "\n",
    "    # Create k-fold CrossValidator (k = numOfFolds)\n",
    "    cv = CrossValidator(estimator = classifier,\n",
    "                        estimatorParamMaps = paramGrid,\n",
    "                        evaluator = MulticlassClassificationEvaluator(),\n",
    "                        numFolds = numOfFolds,\n",
    "                        parallelism = crossValidationParallelism)\n",
    "\n",
    "    # Run cross validations\n",
    "    cvModel = cv.fit(train_set)\n",
    "\n",
    "    # Predict data, based on the best model from cross-validation\n",
    "    predictions = cvModel.transform(test_set)\n",
    "    \n",
    "    # Make prediction and test accuracy\n",
    "    predictionsAndLabelsDF = predictions.select('label', 'prediction') \\\n",
    "    .withColumn(\"label\", predictions[\"label\"].cast(DoubleType()))\n",
    "\n",
    "    # Convert predictionsAndLabels to rdd format\n",
    "    if shift != 0:\n",
    "        predictionsAndLabelsDF = predictionsAndLabelsDF.withColumn(\"prediction\", predictions[\"prediction\"] + shift)\n",
    "    predictionsAndLabelsRDD = predictionsAndLabelsDF.rdd\n",
    "\n",
    "    # Instantiate metrics object\n",
    "    metrics = MulticlassMetrics(predictionsAndLabelsRDD)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluateClassifier(metrics):    \n",
    "    # Overall statistics\n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "\n",
    "    # Statistics by class\n",
    "    for label in sorted(scores):\n",
    "        print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "        print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "\n",
    "    # Weighted stats\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "\n",
    "    # Confusion matrix\n",
    "    confusionMatrix = metrics.confusionMatrix()\n",
    "    np.set_printoptions(formatter={'float': '{: 0.0f}'.format})\n",
    "    print(\"confusionMatrix:\")\n",
    "    print(confusionMatrix)\n",
    "    print(\"Confusion Matrix Values:\")\n",
    "    print(confusionMatrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task6\n",
      "-----\n",
      "\n",
      "\n",
      "Run classifiers on TF vectors, and evaluate the results\n",
      "-------------------------------------------------------\n",
      "Set Naive Bayes classifier\n",
      "Create ParamGrid for Cross Validation of naive bayes, with TF vectors\n",
      "\n",
      "Run naive bayes with binary TF vectors ...\n",
      "\n",
      "Evalute metrics of naive bayes with binary TF vectors\n",
      "Summary Stats\n",
      "Precision = 0.7681700339710352\n",
      "Recall = 0.7681700339710352\n",
      "Class 1 precision = 0.5529860228716645\n",
      "Class 1 recall = 0.6576004835297673\n",
      "Class 2 precision = 0.09624145785876993\n",
      "Class 2 recall = 0.6236162361623616\n",
      "Class 3 precision = 0.16314606741573034\n",
      "Class 3 recall = 0.6459074733096085\n",
      "Class 4 precision = 0.10653126244524094\n",
      "Class 4 recall = 0.5047169811320755\n",
      "Class 5 precision = 0.9786832673080551\n",
      "Class 5 recall = 0.7872135956704264\n",
      "Weighted recall = 0.7681700339710352\n",
      "Weighted precision = 0.9109515726966023\n",
      "Weighted false positive rate = 0.12149993900758382\n",
      "confusionMatrix:\n",
      "DenseMatrix([[ 2176,  475,  236,  120,  302],\n",
      "             [ 35,  169,  18,  18,  31],\n",
      "             [ 37,  59,  363,  55,  48],\n",
      "             [ 52,  47,  129,  535,  297],\n",
      "             [ 1635,  1006,  1479,  4294,  31128]])\n",
      "Confusion Matrix Values:\n",
      "[ 2176  35  37  52  1635  475  169  59  47  1006  236  18  363  129  1479\n",
      "  120  18  55  535  4294  302  31  48  297  31128]\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task6\")\n",
    "displaySubTitle(\"Run classifiers on TF vectors, and evaluate the results\")\n",
    "\n",
    "print(\"Set Naive Bayes classifier\")\n",
    "nb = NaiveBayes(smoothing=1.0, modelType='multinomial', featuresCol='features', labelCol='label')\n",
    "\n",
    "print(\"Create ParamGrid for Cross Validation of naive bayes, with TF vectors\")\n",
    "nbTfParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(nb.smoothing, smoothingGridParam)\n",
    "               .addGrid(hashingTF.numFeatures, numOfFeaturesGridParam) # Number of features\n",
    "               .build())\n",
    "\n",
    "print(\"\\nRun naive bayes with binary TF vectors ...\")\n",
    "nb_binary_tf_metrics = classifyData(nb, train_set_binary_tf, test_set_binary_tf, nbTfParamGrid)\n",
    "\n",
    "print(\"\\nEvalute metrics of naive bayes with binary TF vectors\")\n",
    "evaluateClassifier(nb_binary_tf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task8\n",
      "-----\n",
      "\n",
      "\n",
      "Run classifiers on TF-IDF vectors, and evaluate the results\n",
      "-----------------------------------------------------------\n",
      "Create ParamGrid for Cross Validation of naive bayes, with TF-IDF vectors\n",
      "\n",
      "Run naive bayes with TF-IDF vectors ...\n",
      "\n",
      "Evalute metrics of naive bayes with TF-IDF vectors\n",
      "Summary Stats\n",
      "Precision = 0.7034909708564276\n",
      "Recall = 0.7034909708564276\n",
      "Class 1 precision = 0.6157560355781448\n",
      "Class 1 recall = 0.5358248562582928\n",
      "Class 2 precision = 0.29328018223234625\n",
      "Class 2 recall = 0.3025851938895417\n",
      "Class 3 precision = 0.3267415730337079\n",
      "Class 3 recall = 0.3152645273200347\n",
      "Class 4 precision = 0.30864197530864196\n",
      "Class 4 recall = 0.287409605043575\n",
      "Class 5 precision = 0.8256932654216186\n",
      "Class 5 recall = 0.8520813730897765\n",
      "Weighted recall = 0.7034909708564276\n",
      "Weighted precision = 0.6961888976591001\n",
      "Weighted false positive rate = 0.29163479754103194\n",
      "confusionMatrix:\n",
      "DenseMatrix([[ 2423,  485,  294,  293,  1027],\n",
      "             [ 328,  515,  166,  161,  532],\n",
      "             [ 219,  194,  727,  284,  882],\n",
      "             [ 245,  134,  361,  1550,  3103],\n",
      "             [ 720,  428,  677,  2734,  26262]])\n",
      "Confusion Matrix Values:\n",
      "[ 2423  328  219  245  720  485  515  194  134  428  294  166  727  361\n",
      "  677  293  161  284  1550  2734  1027  532  882  3103  26262]\n"
     ]
    }
   ],
   "source": [
    "displayTitle(\"Task8\")\n",
    "displaySubTitle(\"Run classifiers on TF-IDF vectors, and evaluate the results\")\n",
    "\n",
    "print(\"Create ParamGrid for Cross Validation of naive bayes, with TF-IDF vectors\")\n",
    "nbTfIdfParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(nb.smoothing, smoothingGridParam)\n",
    "               .build())\n",
    "\n",
    "print(\"\\nRun naive bayes with TF-IDF vectors ...\")\n",
    "nb_tf_metrics = classifyData(nb, train_set_tfidf, test_set_tfidf, nbTfIdfParamGrid)\n",
    "\n",
    "print(\"\\nEvalute metrics of naive bayes with TF-IDF vectors\")\n",
    "evaluateClassifier(nb_tf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task7\n",
      "-----\n",
      "\n",
      "\n",
      "Clustering the data\n",
      "-------------------\n",
      "Silhouette with squared euclidean distance = 0.1998191019249972\n",
      "Cluster Centers: \n",
      "[ 0  0  0 ...  0  0  0]\n",
      "[ 0  0  0 ...  0  0  0]\n",
      "Sample 10000 records, in order to check for a possible correlation between cluster_0 and the given scores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'cluster_1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayTitle(\"Task7\")\n",
    "displaySubTitle(\"Clustering the data\")\n",
    "\n",
    "'''\n",
    "We will use k-means with k=2 clusters,\n",
    "and try to find correlation between one cluster and negative reviews,\n",
    "and a correlation between the second cluster and positive reviews.\n",
    "'''\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "kmeansModel = kmeans.fit(train_set_tfidf)\n",
    "\n",
    "# Make predictions\n",
    "kmeansPredictions = kmeansModel.transform(test_set_tfidf)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(kmeansPredictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "# Shows the clusters.\n",
    "centers = kmeansModel.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "# Split the predictions data into 2 dataframes, based on the suitable cluster (0/1)\n",
    "clusters_df = kmeansPredictions.select('label', 'prediction')\n",
    "cluster_0_df = clusters_df.filter('prediction == 0')\n",
    "cluster_1_df = clusters_df.filter('prediction == 1')\n",
    "\n",
    "# Sample the 2 splitted dataframes and convert them to pandas data frame\n",
    "print(\"Sample \" + repr(numOfSamplingDefaultRecords) + \" records, in order to check for a possible correlation between cluster_0 and the given scores\")\n",
    "num_of_cluster0_records = cluster_0_df.count()\n",
    "cluster0_percentage = 1.0 if num_of_cluster0_records < numOfSamplingDefaultRecords else numOfSamplingDefaultRecords / num_of_cluster0_records\n",
    "df_cluster0_pandas = cluster_0_df.sample(False, cluster0_percentage, clusterSeed).toPandas()\n",
    "num_of_cluster1_records = cluster_1_df.count()\n",
    "cluster1_percentage = 1.0 if num_of_cluster1_records < numOfSamplingDefaultRecords else numOfSamplingDefaultRecords / num_of_cluster1_records\n",
    "df_cluster1_pandas = cluster_1_df.sample(False, cluster1_percentage, clusterSeed).toPandas()\n",
    "\n",
    "# Plot 2 histograms of score & score count, corresponding to the 2 splitted dataframes.\n",
    "fig, (left_plt, right_plt) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "left_plt.hist(df_cluster0_pandas['label'],\n",
    "         bins=scores,\n",
    "         density=False,\n",
    "         histtype='bar',\n",
    "         color='b',\n",
    "         edgecolor='k',\n",
    "         alpha=0.5)\n",
    "left_plt.set_title(\"cluster_0\")\n",
    "\n",
    "right_plt.hist(df_cluster1_pandas['label'],\n",
    "         bins=scores,\n",
    "         density=False,\n",
    "         histtype='bar',\n",
    "         color='b',\n",
    "         edgecolor='k',\n",
    "         alpha=0.5)\n",
    "right_plt.set_title(\"cluster_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "Task9\n",
      "-----\n",
      "\n",
      "\n",
      "Comparing the clustering results with the classification results\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFrom the histograms in task 8 we can conclude that there is no correlation between clusters and scores.\\nTherefore negative/positive reviews should not be classified based on these 2 clusters\\n\\non the other hand converting 5 score classes,\\ninto 2 classes (negative/positive reviews) is straight forward.\\nScore 5 is classified as positive review\\nScore 4 is classified as positive review\\nScore 1 is classified as negative review\\nScore 2 is classified as negative review\\nScore 3 is classified as negative review (For the balance, since most of the scores are 5)\\n\\n\\nRemarks:\\nWe have run also logistic regression classifier,\\nbut the performance of Logistic Regression is approximately the same as Naive Bayes classifier.\\nWe have erased the logistic regression code, in order to save some running time.\\nWe also compared binary and non-binary TF vectors for the classifiers - the results are approximately the same.\\nTherefore we also omited this attempt from the final code (in order to save running time).\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayTitle(\"Task9\")\n",
    "displaySubTitle(\"Comparing the clustering results with the classification results\")\n",
    "'''\n",
    "From the histograms in task 8 we can conclude that there is no correlation between clusters and scores.\n",
    "Therefore negative/positive reviews should not be classified based on these 2 clusters\n",
    "\n",
    "on the other hand converting 5 score classes,\n",
    "into 2 classes (negative/positive reviews) is straight forward.\n",
    "Score 5 is classified as positive review\n",
    "Score 4 is classified as positive review\n",
    "Score 1 is classified as negative review\n",
    "Score 2 is classified as negative review\n",
    "Score 3 is classified as negative review (For the balance, since most of the scores are 5)\n",
    "\n",
    "\n",
    "Remarks:\n",
    "We have run also logistic regression classifier,\n",
    "but the performance of Logistic Regression is approximately the same as Naive Bayes classifier.\n",
    "We have erased the logistic regression code, in order to save some running time.\n",
    "We also compared binary and non-binary TF vectors for the classifiers - the results are approximately the same.\n",
    "Therefore we also omited this attempt from the final code (in order to save running time).\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
